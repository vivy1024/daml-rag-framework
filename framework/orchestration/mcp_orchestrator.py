# -*- coding: utf-8 -*-
"""
MCPOrchestrator - MCPå·¥å…·ç¼–æ’å™¨ï¼ˆé€šç”¨æ¡†æ¶ï¼‰

åŸºäºDAGä»»åŠ¡åˆ†è§£ + Kahnæ‹“æ‰‘æ’åº + å¼‚æ­¥å¹¶è¡Œæ‰§è¡Œ

ç†è®ºåŸºç¡€ï¼š
1. Task Decomposition: å°†å¤æ‚æŸ¥è¯¢æ‹†åˆ†ä¸ºå¯ç‹¬ç«‹æ‰§è¡Œçš„å­ä»»åŠ¡
2. Dependency Resolution: ä½¿ç”¨DAGè¡¨ç¤ºä»»åŠ¡ä¾èµ–å…³ç³»
3. Topological Sorting (Kahn's Algorithm): ç¡®å®šåˆæ³•çš„æ‰§è¡Œé¡ºåº
4. Asynchronous I/O (asyncio): å¹¶è¡Œæ‰§è¡Œæ— ä¾èµ–ä»»åŠ¡ï¼Œæå‡ååé‡
5. TTL Caching: é¿å…çŸ­æ—¶é—´å†…é‡å¤è°ƒç”¨ç›¸åŒMCPå·¥å…·

è®ºæ–‡å‚è€ƒï¼š
- "Airflow" (Apache, 2014): DAGä»»åŠ¡ç¼–æ’æ¡†æ¶
- "Temporal" (Uber, 2019): åˆ†å¸ƒå¼å·¥ä½œæµå¼•æ“
- "Kahn's Algorithm" (1962): æ‹“æ‰‘æ’åºç»å…¸ç®—æ³•

è®¾è®¡åŸåˆ™ï¼š
- é¢†åŸŸæ— å…³ï¼šä¸ä¾èµ–ç‰¹å®šMCPå·¥å…·
- è‡ªåŠ¨å¹¶è¡Œï¼šè¯†åˆ«å¹¶è¡Œæœºä¼šï¼Œæœ€å¤§åŒ–ååé‡
- å®¹é”™æœºåˆ¶ï¼šå•ä¸ªä»»åŠ¡å¤±è´¥ä¸å½±å“å…¶ä»–ä»»åŠ¡

æ•°å­¦åŸç†ï¼ˆKahnæ‹“æ‰‘æ’åºï¼‰ï¼š
    1. è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹çš„å…¥åº¦ï¼ˆä¾èµ–æ•°é‡ï¼‰
    2. å°†å…¥åº¦ä¸º0çš„èŠ‚ç‚¹åŠ å…¥é˜Ÿåˆ—
    3. ä»é˜Ÿåˆ—å–å‡ºèŠ‚ç‚¹ï¼Œæ‰§è¡Œå¹¶å‡å°‘å…¶åç»§èŠ‚ç‚¹çš„å…¥åº¦
    4. é‡å¤ç›´åˆ°æ‰€æœ‰èŠ‚ç‚¹æ‰§è¡Œå®Œæ¯•
    
    æ—¶é—´å¤æ‚åº¦ï¼šO(V + E)ï¼ŒV=èŠ‚ç‚¹æ•°ï¼ŒE=è¾¹æ•°

Example:
    >>> orchestrator = MCPOrchestrator(metadata_db)
    >>> 
    >>> # å®šä¹‰ä»»åŠ¡DAG
    >>> tasks = [
    ...     Task("get_profile", "user-profile-stdio", "get_user_profile", 
    ...          params={"user_id": "zhangsan"}),
    ...     Task("get_exercises", "professional-fitness-coach-stdio", "search-exercises-semantic",
    ...          params={"muscle_group": "chest"}, depends_on=["get_profile"]),
    ...     Task("create_plan", "enhanced-coach-stdio", "create_training_plan",
    ...          params={}, depends_on=["get_profile", "get_exercises"])
    ... ]
    >>> 
    >>> # æ‰§è¡Œç¼–æ’
    >>> results = await orchestrator.execute(tasks)
    >>> print(results["create_plan"])

ä½œè€…ï¼šBUILD_BODY Team
ç‰ˆæœ¬ï¼šv1.0.0
æ—¥æœŸï¼š2025-10-28
"""

import asyncio
import hashlib
import json
import logging
import time
from enum import Enum
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, field
from pathlib import Path

logger = logging.getLogger(__name__)


class TaskStatus(Enum):
    """ä»»åŠ¡çŠ¶æ€"""
    PENDING = "pending"       # ç­‰å¾…æ‰§è¡Œ
    RUNNING = "running"       # æ‰§è¡Œä¸­
    COMPLETED = "completed"   # å·²å®Œæˆ
    FAILED = "failed"         # å¤±è´¥
    SKIPPED = "skipped"       # è·³è¿‡ï¼ˆä¾èµ–å¤±è´¥ï¼‰


@dataclass
class Task:
    """
    ä»»åŠ¡å®šä¹‰
    
    Attributes:
        task_id: ä»»åŠ¡å”¯ä¸€æ ‡è¯†
        mcp_server: MCPæœåŠ¡å™¨åç§°ï¼ˆä¾‹å¦‚ï¼š"user-profile-stdio"ï¼‰
        tool_name: å·¥å…·åç§°ï¼ˆä¾‹å¦‚ï¼š"get_user_profile"ï¼‰
        params: å·¥å…·å‚æ•°ï¼ˆå­—å…¸ï¼‰
        depends_on: ä¾èµ–çš„ä»»åŠ¡IDåˆ—è¡¨ï¼ˆé»˜è®¤ä¸ºç©ºï¼‰
        status: ä»»åŠ¡çŠ¶æ€ï¼ˆé»˜è®¤PENDINGï¼‰
        result: æ‰§è¡Œç»“æœï¼ˆæˆåŠŸåå¡«å……ï¼‰
        error: é”™è¯¯ä¿¡æ¯ï¼ˆå¤±è´¥æ—¶å¡«å……ï¼‰
        start_time: å¼€å§‹æ—¶é—´
        end_time: ç»“æŸæ—¶é—´
    
    Example:
        >>> task = Task(
        ...     task_id="get_profile",
        ...     mcp_server="user-profile-stdio",
        ...     tool_name="get_user_profile",
        ...     params={"user_id": "zhangsan"},
        ...     depends_on=[]
        ... )
    """
    task_id: str
    mcp_server: str
    tool_name: str
    params: Dict[str, Any]
    depends_on: List[str] = field(default_factory=list)
    status: TaskStatus = TaskStatus.PENDING
    result: Optional[Any] = None
    error: Optional[str] = None
    start_time: Optional[float] = None
    end_time: Optional[float] = None


class MCPOrchestrator:
    """
    MCPå·¥å…·ç¼–æ’å™¨ï¼ˆé€šç”¨æ¡†æ¶ï¼‰
    
    æ ¸å¿ƒç®—æ³•ï¼šKahnæ‹“æ‰‘æ’åº + asyncioå¹¶è¡Œæ‰§è¡Œ
    
    å·¥ä½œæµç¨‹ï¼š
    1. æ„å»ºDAGå›¾ï¼ˆä»»åŠ¡ + ä¾èµ–å…³ç³»ï¼‰
    2. æ£€æµ‹å¾ªç¯ä¾èµ–ï¼ˆå¦‚æœå­˜åœ¨åˆ™æŠ¥é”™ï¼‰
    3. Kahnæ‹“æ‰‘æ’åºï¼ˆç¡®å®šæ‰§è¡Œé¡ºåºï¼‰
    4. å¼‚æ­¥å¹¶è¡Œæ‰§è¡Œï¼ˆæ— ä¾èµ–ä»»åŠ¡å¹¶è¡Œï¼‰
    5. ç»“æœèšåˆ
    
    è®¾è®¡åŸåˆ™ï¼š
    - é¢†åŸŸæ— å…³ï¼šä¸ä¾èµ–ç‰¹å®šMCPå·¥å…·
    - è‡ªåŠ¨å¹¶è¡Œï¼šè¯†åˆ«å¹¶è¡Œæœºä¼š
    - ç¼“å­˜ä¼˜åŒ–ï¼šTTLç¼“å­˜é¿å…é‡å¤è°ƒç”¨
    
    Example:
        >>> orchestrator = MCPOrchestrator(metadata_db)
        >>> 
        >>> tasks = [
        ...     Task("task1", "mcp1", "tool1", {}),
        ...     Task("task2", "mcp2", "tool2", {}, depends_on=["task1"]),
        ...     Task("task3", "mcp3", "tool3", {}, depends_on=["task1"]),
        ...     Task("task4", "mcp4", "tool4", {}, depends_on=["task2", "task3"])
        ... ]
        >>> 
        >>> results = await orchestrator.execute(tasks)
        >>> # task1 å…ˆæ‰§è¡Œ
        >>> # task2 å’Œ task3 å¹¶è¡Œæ‰§è¡Œ
        >>> # task4 æœ€åæ‰§è¡Œ
    """
    
    def __init__(
        self,
        metadata_db,  # MetadataDBå®ä¾‹
        cache_ttl: int = 300,  # ç¼“å­˜TTLï¼ˆç§’ï¼‰
        max_parallel: int = 5,   # æœ€å¤§å¹¶è¡Œæ•°
        mcp_client_pool = None,  # ConfigurableMCPClientå®ä¾‹ï¼ˆå¯é€‰ï¼‰
        user_profile_provider = None,  # ç”¨æˆ·æ¡£æ¡ˆæä¾›å™¨ï¼ˆå¯é€‰ï¼Œç”±åº”ç”¨å±‚æ³¨å…¥ï¼‰
        tool_registry = None  # å·¥å…·æ³¨å†Œå™¨ï¼ˆå¯é€‰ï¼Œç”±åº”ç”¨å±‚æ³¨å…¥é¢†åŸŸç‰¹å®šå·¥å…·ï¼‰
    ):
        """
        åˆå§‹åŒ–ç¼–æ’å™¨

        Args:
            metadata_db: MetadataDBå®ä¾‹ï¼ˆç”¨äºç¼“å­˜ï¼‰
            cache_ttl: ç¼“å­˜TTLï¼ˆé»˜è®¤300ç§’ï¼‰
            max_parallel: æœ€å¤§å¹¶è¡Œä»»åŠ¡æ•°ï¼ˆé»˜è®¤5ï¼‰
            mcp_client_pool: ConfigurableMCPClientå®ä¾‹ï¼ˆå¯é€‰ï¼Œä½¿ç”¨stdioåè®®ï¼‰
            user_profile_provider: ç”¨æˆ·æ¡£æ¡ˆæä¾›å™¨ï¼ˆå¯é€‰ï¼Œç”±åº”ç”¨å±‚æ³¨å…¥ï¼Œä¿æŒFrameworkå±‚é¢†åŸŸæ— å…³æ€§ï¼‰
            tool_registry: å·¥å…·æ³¨å†Œå™¨ï¼ˆå¯é€‰ï¼Œç”±åº”ç”¨å±‚æ³¨å…¥é¢†åŸŸç‰¹å®šå·¥å…·ï¼Œä¿æŒFrameworkå±‚é¢†åŸŸæ— å…³æ€§ï¼‰
        """
        self.metadata_db = metadata_db
        self.cache_ttl = cache_ttl
        self.max_parallel = max_parallel
        self.semaphore = asyncio.Semaphore(max_parallel)

        # ç”¨æˆ·æ¡£æ¡ˆæä¾›å™¨ï¼ˆç”±åº”ç”¨å±‚æ³¨å…¥ï¼Œä¿æŒFrameworkå±‚é¢†åŸŸæ— å…³æ€§ï¼‰
        self.user_profile_provider = user_profile_provider

        # å·¥å…·æ³¨å†Œå™¨ï¼ˆç”±åº”ç”¨å±‚æ³¨å…¥ï¼Œä¿æŒFrameworkå±‚é¢†åŸŸæ— å…³æ€§ï¼‰
        self.tool_registry = tool_registry

        # MCPå®¢æˆ·ç«¯æ± ï¼ˆä»…æ”¯æŒStdioæ¨¡å¼ï¼‰
        self.mcp_client_pool = mcp_client_pool

        # ç¡®å®šMCPæ¨¡å¼
        if self.mcp_client_pool:
            mcp_mode = "stdio"
        else:
            mcp_mode = "local"

        logger.info(
            f"MCPOrchestrator v3.0 initialized: cache_ttl={cache_ttl}s, "
            f"max_parallel={max_parallel}, mcp_mode={mcp_mode}"
        )
    
    async def execute(
        self,
        tasks: List[Task],
        user_id: Optional[str] = None,
        preloaded_results: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œä»»åŠ¡ç¼–æ’ï¼ˆå¼‚æ­¥ï¼‰
        
        å·¥ä½œæµç¨‹ï¼š
        1. æ„å»ºä»»åŠ¡å­—å…¸
        2. æ£€æµ‹å¾ªç¯ä¾èµ–
        3. Kahnæ‹“æ‰‘æ’åº
        4. å¹¶è¡Œæ‰§è¡Œæ¯ä¸€å±‚çº§çš„ä»»åŠ¡
        5. è¿”å›ç»“æœ
        
        Args:
            tasks: ä»»åŠ¡åˆ—è¡¨
            user_id: ç”¨æˆ·IDï¼ˆç”¨äºç¼“å­˜å‘½åç©ºé—´ï¼‰
            preloaded_results: é¢„åŠ è½½çš„ç»“æœæ•°æ®ï¼ˆv3.2.1æ–°å¢ï¼‰
                ç”¨äºæ³¨å…¥å·²çŸ¥æ•°æ®ï¼Œé¿å…é‡å¤æ‰§è¡Œä»»åŠ¡
                ä¾‹å¦‚: {"get_user_profile": {...}}
        
        Returns:
            Dict[str, Any]: ä»»åŠ¡ç»“æœå­—å…¸
                {
                    "task1": {...},
                    "task2": {...},
                    ...
                }
        
        Raises:
            ValueError: å¦‚æœå­˜åœ¨å¾ªç¯ä¾èµ–
        
        Example:
            >>> tasks = [
            ...     Task("t1", "mcp1", "tool1", {}),
            ...     Task("t2", "mcp2", "tool2", {}, depends_on=["t1"])
            ... ]
            >>> results = await orchestrator.execute(tasks)
        """
        logger.info(f"Starting orchestration: {len(tasks)} tasks")
        
        # 1. æ„å»ºä»»åŠ¡å­—å…¸
        task_dict = {t.task_id: t for t in tasks}
        
        # 2. æ£€æµ‹å¾ªç¯ä¾èµ–
        if self._has_cycle(task_dict):
            raise ValueError("Circular dependency detected in task graph")
        
        # 3. Kahnæ‹“æ‰‘æ’åº
        execution_order = self._topological_sort(task_dict)
        
        logger.debug(f"Execution order: {execution_order}")
        
        # 4. åˆå§‹åŒ–ç»“æœï¼ˆåŒ…å«é¢„åŠ è½½æ•°æ®ï¼‰
        results = preloaded_results.copy() if preloaded_results else {}
        
        if preloaded_results:
            logger.info(
                f"âœ… [é¢„åŠ è½½æ³¨å…¥] åˆå§‹åŒ– {len(preloaded_results)} ä¸ªé¢„åŠ è½½ç»“æœ: "
                f"{list(preloaded_results.keys())}"
            )
        
        for level_tasks in execution_order:
            # å¹¶è¡Œæ‰§è¡ŒåŒä¸€å±‚çº§çš„ä»»åŠ¡
            level_results = await asyncio.gather(
                *[
                    self._execute_task(
                        task_dict[task_id],
                        results,
                        user_id
                    )
                    for task_id in level_tasks
                ],
                return_exceptions=True
            )
            
            # æ”¶é›†ç»“æœ
            for task_id, result in zip(level_tasks, level_results):
                if isinstance(result, Exception):
                    task_dict[task_id].status = TaskStatus.FAILED
                    task_dict[task_id].error = str(result)
                    logger.error(
                        f"Task {task_id} failed: {result}"
                    )
                else:
                    results[task_id] = result
        
        logger.info(
            f"Orchestration completed: "
            f"{sum(1 for t in tasks if t.status == TaskStatus.COMPLETED)}/{len(tasks)} succeeded"
        )
        
        return results
    
    def inject_preloaded_data(
        self,
        results: Dict[str, Any],
        preloaded_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        æ³¨å…¥é¢„åŠ è½½æ•°æ®åˆ°ç»“æœä¸­ï¼ˆv3.2.0æ–°å¢ï¼‰
        
        ç”¨äºå°†å¤–éƒ¨é¢„åŠ è½½çš„æ•°æ®ï¼ˆå¦‚ç”¨æˆ·æ¡£æ¡ˆï¼‰æ³¨å…¥åˆ°DAGæ‰§è¡Œç»“æœä¸­ï¼Œ
        é¿å…é‡å¤è°ƒç”¨MCPå·¥å…·ã€‚
        
        Args:
            results: å½“å‰æ‰§è¡Œç»“æœ
            preloaded_data: é¢„åŠ è½½æ•°æ®å­—å…¸
                {
                    "get_user_profile": {...},  # é¢„åŠ è½½çš„ç”¨æˆ·æ¡£æ¡ˆ
                    "cached_exercises": [...]   # é¢„åŠ è½½çš„åŠ¨ä½œåº“
                }
        
        Returns:
            Dict[str, Any]: åˆå¹¶åçš„ç»“æœï¼ˆä¸ä¿®æ”¹åŸresultsï¼‰
        
        Example:
            >>> results = await orchestrator.execute(tasks)
            >>> preloaded = {"get_user_profile": {"age": 25, "weight": 70}}
            >>> final_results = orchestrator.inject_preloaded_data(
            ...     results, preloaded
            ... )
            >>> # final_results åŒ…å« results + preloaded æ•°æ®
        
        æ³¨æ„ï¼š
            - é¢„åŠ è½½æ•°æ®ä¼˜å…ˆçº§é«˜äºæ‰§è¡Œç»“æœï¼ˆä¼šè¦†ç›–ï¼‰
            - ä»…æ³¨å…¥ä¸å­˜åœ¨çš„é”®ï¼Œé¿å…è¦†ç›–å·²æ‰§è¡Œçš„ç»“æœ
            - è®°å½•æ³¨å…¥æ—¥å¿—ï¼Œä¾¿äºè°ƒè¯•
        """
        # åˆ›å»ºåˆå¹¶åçš„ç»“æœï¼ˆæµ…æ‹·è´ï¼Œé¿å…ä¿®æ”¹åŸæ•°æ®ï¼‰
        merged_results = {**results}
        
        injected_count = 0
        for key, value in preloaded_data.items():
            if key not in merged_results:
                # ä»…æ³¨å…¥ä¸å­˜åœ¨çš„é”®
                merged_results[key] = value
                injected_count += 1
                logger.debug(f"âœ… [æ•°æ®æ³¨å…¥] æ³¨å…¥é¢„åŠ è½½æ•°æ®: {key}")
            else:
                logger.debug(
                    f"âš ï¸ [æ•°æ®æ³¨å…¥] è·³è¿‡å·²å­˜åœ¨çš„é”®: {key} "
                    "(ä¿ç•™æ‰§è¡Œç»“æœï¼Œä¸è¦†ç›–)"
                )
        
        if injected_count > 0:
            logger.info(
                f"ğŸ“Š [æ•°æ®æ³¨å…¥] æˆåŠŸæ³¨å…¥ {injected_count} ä¸ªé¢„åŠ è½½æ•°æ®é¡¹"
            )
        
        return merged_results
    
    def _has_cycle(self, task_dict: Dict[str, Task]) -> bool:
        """
        æ£€æµ‹å¾ªç¯ä¾èµ–ï¼ˆDFSï¼‰
        
        ç®—æ³•ï¼šæ·±åº¦ä¼˜å…ˆæœç´¢ï¼Œä½¿ç”¨ä¸‰è‰²æ ‡è®°
        - WHITEï¼ˆ0ï¼‰: æœªè®¿é—®
        - GRAYï¼ˆ1ï¼‰: è®¿é—®ä¸­
        - BLACKï¼ˆ2ï¼‰: å·²å®Œæˆ
        
        å¦‚æœè®¿é—®åˆ°GRAYèŠ‚ç‚¹ï¼Œè¯´æ˜å­˜åœ¨ç¯
        
        Args:
            task_dict: ä»»åŠ¡å­—å…¸
        
        Returns:
            bool: Trueè¡¨ç¤ºæœ‰ç¯ï¼ŒFalseè¡¨ç¤ºæ— ç¯
        """
        WHITE, GRAY, BLACK = 0, 1, 2
        color = {task_id: WHITE for task_id in task_dict}
        
        def dfs(task_id: str) -> bool:
            if color[task_id] == GRAY:
                return True  # æ‰¾åˆ°ç¯
            
            if color[task_id] == BLACK:
                return False  # å·²è®¿é—®è¿‡
            
            color[task_id] = GRAY
            
            for dep in task_dict[task_id].depends_on:
                if dep in task_dict and dfs(dep):
                    return True
            
            color[task_id] = BLACK
            return False
        
        # æ£€æŸ¥æ‰€æœ‰èŠ‚ç‚¹
        for task_id in task_dict:
            if color[task_id] == WHITE:
                if dfs(task_id):
                    return True
        
        return False
    
    def _topological_sort(
        self,
        task_dict: Dict[str, Task]
    ) -> List[List[str]]:
        """
        Kahnæ‹“æ‰‘æ’åºï¼ˆåˆ†å±‚ï¼‰
        
        è¿”å›åˆ†å±‚çš„ä»»åŠ¡IDåˆ—è¡¨ï¼ŒåŒä¸€å±‚çº§çš„ä»»åŠ¡å¯ä»¥å¹¶è¡Œæ‰§è¡Œ
        
        ç®—æ³•ï¼š
        1. è®¡ç®—æ¯ä¸ªä»»åŠ¡çš„å…¥åº¦ï¼ˆä¾èµ–æ•°é‡ï¼‰
        2. å°†å…¥åº¦ä¸º0çš„ä»»åŠ¡åŠ å…¥ç¬¬ä¸€å±‚
        3. æ‰§è¡Œç¬¬ä¸€å±‚ä»»åŠ¡åï¼Œæ›´æ–°ä¾èµ–ä»»åŠ¡çš„å…¥åº¦
        4. å°†æ–°çš„å…¥åº¦ä¸º0çš„ä»»åŠ¡åŠ å…¥ä¸‹ä¸€å±‚
        5. é‡å¤ç›´åˆ°æ‰€æœ‰ä»»åŠ¡åˆ†é…å®Œæ¯•
        
        Args:
            task_dict: ä»»åŠ¡å­—å…¸
        
        Returns:
            List[List[str]]: åˆ†å±‚çš„ä»»åŠ¡IDåˆ—è¡¨
                [
                    ["task1", "task2"],  # ç¬¬1å±‚ï¼ˆå¹¶è¡Œï¼‰
                    ["task3"],           # ç¬¬2å±‚
                    ["task4", "task5"]   # ç¬¬3å±‚ï¼ˆå¹¶è¡Œï¼‰
                ]
        
        Example:
            >>> # DAG: t1 â†’ t2 â†’ t4
            >>> #      t1 â†’ t3 â†’ t4
            >>> result = orchestrator._topological_sort(task_dict)
            >>> # [[t1], [t2, t3], [t4]]
        """
        # è®¡ç®—å…¥åº¦
        in_degree = {task_id: 0 for task_id in task_dict}
        
        for task in task_dict.values():
            for dep in task.depends_on:
                if dep in in_degree:
                    in_degree[task.task_id] += 1
        
        # åˆ†å±‚æ‰§è¡Œ
        levels = []
        remaining = set(task_dict.keys())
        
        while remaining:
            # æ‰¾åˆ°å½“å‰å…¥åº¦ä¸º0çš„ä»»åŠ¡
            current_level = [
                task_id for task_id in remaining
                if in_degree[task_id] == 0
            ]
            
            if not current_level:
                # ä¸åº”è¯¥å‘ç”Ÿï¼ˆå·²æ£€æµ‹ç¯ï¼‰
                break
            
            levels.append(current_level)
            
            # æ›´æ–°å…¥åº¦
            for task_id in current_level:
                remaining.remove(task_id)
                
                # å‡å°‘åç»§ä»»åŠ¡çš„å…¥åº¦
                for other_id in remaining:
                    if task_id in task_dict[other_id].depends_on:
                        in_degree[other_id] -= 1
        
        return levels
    
    async def _execute_task(
        self,
        task: Task,
        results: Dict[str, Any],
        user_id: Optional[str]
    ) -> Any:
        """
        æ‰§è¡Œå•ä¸ªä»»åŠ¡ï¼ˆå¼‚æ­¥ï¼‰
        
        å·¥ä½œæµç¨‹ï¼š
        1. æ£€æŸ¥ä¾èµ–æ˜¯å¦éƒ½æˆåŠŸ
        2. æ£€æŸ¥ç¼“å­˜
        3. æ‰§è¡ŒMCPå·¥å…·è°ƒç”¨ï¼ˆæ¨¡æ‹Ÿï¼‰
        4. æ›´æ–°ç¼“å­˜
        5. è¿”å›ç»“æœ
        
        Args:
            task: ä»»åŠ¡å¯¹è±¡
            results: å·²å®Œæˆä»»åŠ¡çš„ç»“æœå­—å…¸
            user_id: ç”¨æˆ·ID
        
        Returns:
            Any: ä»»åŠ¡æ‰§è¡Œç»“æœ
        
        Raises:
            RuntimeError: å¦‚æœä¾èµ–ä»»åŠ¡å¤±è´¥
        """
        async with self.semaphore:
            task.status = TaskStatus.RUNNING
            task.start_time = time.time()
            
            try:
                # æ£€æŸ¥ä¾èµ–
                for dep_id in task.depends_on:
                    if dep_id not in results:
                        raise RuntimeError(
                            f"Dependency {dep_id} not completed"
                        )
                
                # æ£€æŸ¥ç¼“å­˜
                cache_key = self._build_cache_key(
                    task.mcp_server,
                    task.tool_name,
                    task.params,
                    user_id
                )
                
                cached_result = self.metadata_db.get_cache(cache_key)
                
                if cached_result is not None:
                    logger.info(
                        f"Cache hit for task {task.task_id}: {cache_key}"
                    )
                    task.result = cached_result
                    task.status = TaskStatus.COMPLETED
                    task.end_time = time.time()
                    return cached_result
                
                # æ‰§è¡ŒMCPå·¥å…·è°ƒç”¨ï¼ˆæ¨¡æ‹Ÿï¼‰
                logger.info(
                    f"Executing task {task.task_id}: "
                    f"{task.mcp_server}.{task.tool_name}"
                )

                # ç¡®ä¿å‚æ•°æ˜¯å¯åºåˆ—åŒ–çš„
                serializable_params = {}
                for key, value in task.params.items():
                    if hasattr(value, 'to_dict'):
                        # å¦‚æœå¯¹è±¡æœ‰to_dictæ–¹æ³•ï¼Œä½¿ç”¨å®ƒ
                        serializable_params[key] = value.to_dict()
                    elif isinstance(value, dict):
                        # å¦‚æœæ˜¯å­—å…¸ï¼Œé€’å½’å¤„ç†åµŒå¥—å¯¹è±¡
                        serializable_params[key] = self._make_dict_serializable(value)
                    elif hasattr(value, '__dict__'):
                        # å¯¹äºæœ‰å±æ€§çš„å¯¹è±¡ï¼Œå°è¯•å®‰å…¨åºåˆ—åŒ–
                        serializable_params[key] = str(value)
                    else:
                        # å¯¹äºå…¶ä»–ç±»å‹ï¼Œç›´æ¥ä½¿ç”¨
                        serializable_params[key] = value

                result = await self._call_mcp_tool(
                    task.mcp_server,
                    task.tool_name,
                    serializable_params
                )
                
                # æ›´æ–°ç¼“å­˜
                # ç”Ÿæˆparams_hashï¼ˆç”¨äºMetadataDB.set_cacheï¼‰
                # ç¡®ä¿æ‰€æœ‰å‚æ•°éƒ½æ˜¯JSONå¯åºåˆ—åŒ–çš„
                # ä½¿ç”¨å·²ç»åœ¨ä¸Šé¢å¤„ç†å¥½çš„serializable_params
                # å†æ¬¡ç¡®ä¿æ‰€æœ‰å€¼éƒ½æ˜¯å¯åºåˆ—åŒ–çš„ï¼ˆåŒé‡ä¿æŠ¤ï¼‰

                # é¢å¤–åºåˆ—åŒ–æ£€æŸ¥ï¼Œé˜²æ­¢UserProfileç­‰å¯¹è±¡æ¼ç½‘
                def deep_serialize(obj):
                    if hasattr(obj, 'to_dict'):
                        return obj.to_dict()
                    elif isinstance(obj, dict):
                        return {k: deep_serialize(v) for k, v in obj.items()}
                    elif isinstance(obj, (list, tuple)):
                        return [deep_serialize(item) for item in obj]
                    elif hasattr(obj, '__dict__'):
                        return str(obj)  # å¯¹äºå…¶ä»–å¯¹è±¡ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
                    else:
                        return obj

                # æ·±åº¦åºåˆ—åŒ–æ‰€æœ‰å‚æ•°å€¼
                fully_serializable_params = {}
                for k, v in serializable_params.items():
                    fully_serializable_params[k] = deep_serialize(v)

                sorted_params = sorted(fully_serializable_params.items())
                params_json = json.dumps(sorted_params, sort_keys=True)
                params_hash = hashlib.md5(params_json.encode()).hexdigest()
                
                # ç¡®ä¿resultä¹Ÿæ˜¯å¯åºåˆ—åŒ–çš„
                serializable_result = self._make_dict_serializable(result)

                self.metadata_db.set_cache(
                    cache_key=cache_key,
                    tool_name=task.tool_name,
                    params_hash=params_hash,
                    result=serializable_result,
                    ttl=self.cache_ttl
                )
                
                # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                task.result = result
                task.status = TaskStatus.COMPLETED
                task.end_time = time.time()
                
                logger.info(
                    f"Task {task.task_id} completed in "
                    f"{task.end_time - task.start_time:.2f}s"
                )
                
                return result
                
            except Exception as e:
                task.status = TaskStatus.FAILED
                task.error = str(e)
                task.end_time = time.time()
                
                logger.error(
                    f"Task {task.task_id} failed: {e}"
                )
                
                raise
    
    def _make_dict_serializable(self, obj: Any) -> Any:
        """
        é€’å½’å¤„ç†å­—å…¸ä¸­çš„å¯¹è±¡ï¼Œç¡®ä¿å…¶å¯åºåˆ—åŒ–

        Args:
            obj: éœ€è¦å¤„ç†çš„å¯¹è±¡ï¼ˆå­—å…¸ã€åˆ—è¡¨æˆ–å…¶ä»–ç±»å‹ï¼‰

        Returns:
            Any: å¤„ç†åçš„å¯åºåˆ—åŒ–å¯¹è±¡
        """
        if obj is None:
            return None

        if hasattr(obj, 'to_dict'):
            # å¦‚æœå¯¹è±¡æœ‰to_dictæ–¹æ³•ï¼Œä½¿ç”¨å®ƒ
            return obj.to_dict()
        elif isinstance(obj, dict):
            # é€’å½’å¤„ç†å­—å…¸
            result = {}
            for key, value in obj.items():
                # ç¡®ä¿keyæ˜¯å­—ç¬¦ä¸²
                if not isinstance(key, str):
                    key = str(key)
                result[key] = self._make_dict_serializable(value)
            return result
        elif isinstance(obj, (list, tuple)):
            # é€’å½’å¤„ç†åˆ—è¡¨/å…ƒç»„
            return [self._make_dict_serializable(item) for item in obj]
        elif hasattr(obj, '__dict__'):
            # å¯¹äºæœ‰å±æ€§çš„å¯¹è±¡ï¼Œå°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            try:
                return str(obj)
            except Exception:
                return f"<{type(obj).__name__} object>"
        elif isinstance(obj, (str, int, float, bool)):
            # åŸºæœ¬ç±»å‹ç›´æ¥è¿”å›
            return obj
        else:
            # å…¶ä»–ç±»å‹å°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            try:
                return str(obj)
            except Exception:
                return f"<{type(obj).__name__} object>"

    def _build_cache_key(
        self,
        mcp_server: str,
        tool_name: str,
        params: Dict[str, Any],
        user_id: Optional[str]
    ) -> str:
        """
        æ„å»ºç¼“å­˜é”®
        
        æ ¼å¼ï¼šmcp://{user_id}/{mcp_server}/{tool_name}?{params}
        
        Args:
            mcp_server: MCPæœåŠ¡å™¨åç§°
            tool_name: å·¥å…·åç§°
            params: å‚æ•°å­—å…¸
            user_id: ç”¨æˆ·IDï¼ˆå¯é€‰ï¼‰
        
        Returns:
            str: ç¼“å­˜é”®
        
        Example:
            >>> key = orchestrator._build_cache_key(
            ...     "user-profile-stdio",
            ...     "get_user_profile",
            ...     {"user_id": "zhangsan"},
            ...     "zhangsan"
            ... )
            >>> # "mcp://zhangsan/user-profile-stdio/get_user_profile?user_id=zhangsan"
        """
        # æ’åºå‚æ•°ä»¥ä¿è¯ä¸€è‡´æ€§
        sorted_params = sorted(params.items())
        params_str = "&".join(f"{k}={v}" for k, v in sorted_params)
        
        user_prefix = f"{user_id}/" if user_id else ""
        
        return f"mcp://{user_prefix}{mcp_server}/{tool_name}?{params_str}"
    
    async def call_tool(
        self,
        mcp_server: str,
        tool_name: str,
        params: Dict[str, Any]
    ) -> Any:
        """
        è°ƒç”¨MCPå·¥å…·ï¼ˆå…¬å¼€æ–¹æ³•ï¼‰- v3.0ä»…æ”¯æŒStdioæ¨¡å¼

        æ ¹æ®å®¢æˆ·ç«¯æ± ç±»å‹ï¼Œè‡ªåŠ¨åˆ‡æ¢Stdioæˆ–æœ¬åœ°å®ç°

        Args:
            mcp_server: MCPæœåŠ¡å™¨åç§°
            tool_name: å·¥å…·åç§°
            params: å‚æ•°å­—å…¸

        Returns:
            Any: å·¥å…·è°ƒç”¨ç»“æœ

        Raises:
            RuntimeError: å¦‚æœMCPè°ƒç”¨å¤±è´¥
        """
        return await self._call_mcp_tool(mcp_server, tool_name, params)

    async def _call_mcp_tool(
        self,
        mcp_server: str,
        tool_name: str,
        params: Dict[str, Any]
    ) -> Any:
        """
        è°ƒç”¨MCPå·¥å…·ï¼ˆç§æœ‰æ–¹æ³•ï¼‰- v3.0ä»…æ”¯æŒStdioæ¨¡å¼

        æ ¹æ®å®¢æˆ·ç«¯æ± ç±»å‹ï¼Œè‡ªåŠ¨åˆ‡æ¢Stdioæˆ–æœ¬åœ°å®ç°

        Args:
            mcp_server: MCPæœåŠ¡å™¨åç§°
            tool_name: å·¥å…·åç§°
            params: å‚æ•°å­—å…¸

        Returns:
            Any: å·¥å…·è°ƒç”¨ç»“æœ

        Raises:
            RuntimeError: å¦‚æœMCPè°ƒç”¨å¤±è´¥
        """
        # Stdioå®¢æˆ·ç«¯æ¨¡å¼
        if self.mcp_client_pool:
            try:
                logger.debug(
                    f"Calling Stdio MCP tool: server={mcp_server}, tool={tool_name}"
                )

                # ä½¿ç”¨ConfigurableMCPClientçš„requestæ–¹æ³•
                result = await self.mcp_client_pool.request({
                    "server_name": mcp_server,
                    "tool_name": tool_name,
                    "arguments": params
                })

                logger.debug(
                    f"Stdio MCP tool completed: server={mcp_server}, tool={tool_name}"
                )

                return result

            except Exception as e:
                logger.error(
                    f"Stdio MCP tool call failed: server={mcp_server}, "
                    f"tool={tool_name}, error={e}"
                )
                # é™çº§åˆ°æœ¬åœ°å®ç°è€Œä¸æ˜¯æŠ¥é”™
                logger.info(f"Falling back to LOCAL implementation: server={mcp_server}, tool={tool_name}")
                return await self._call_local_implementation(
                    mcp_server, tool_name, params
                )

        # æœ¬åœ°å®ç°æ¨¡å¼ï¼ˆç›´æ¥è°ƒç”¨GraphRAGå’ŒBackendClientï¼‰
        else:
            logger.info(
                f"Using LOCAL implementation: server={mcp_server}, "
                f"tool={tool_name}"
            )

            # æ ¹æ®å·¥å…·åç§°ç›´æ¥è°ƒç”¨æœ¬åœ°å®ç°
            return await self._call_local_implementation(
                mcp_server, tool_name, params
            )
    
    async def _call_local_implementation(
        self,
        mcp_server: str,
        tool_name: str,
        params: Dict[str, Any]
    ) -> Any:
        """
        æœ¬åœ°å®ç°æ¨¡å¼ï¼šç›´æ¥è°ƒç”¨GraphRAGã€BackendClientå’ŒHTTP API

        æ›¿ä»£çœŸå®çš„MCPæœåŠ¡å™¨è°ƒç”¨ï¼Œç”¨äºBUILD_BODYé¡¹ç›®ï¼ˆv4.0ç»Ÿä¸€DAML-RAG Serveræ¶æ„ï¼‰

        Args:
            mcp_server: MCPæœåŠ¡å™¨åç§°ï¼ˆå½“å‰æ¶æ„ä½¿ç”¨å†…ç½®æœ¬åœ°å®ç°ï¼‰
            tool_name: å·¥å…·åç§°
            params: å‚æ•°å­—å…¸

        Returns:
            Any: å·¥å…·è°ƒç”¨ç»“æœ
        """
        try:
            # 1. ç”¨æˆ·æ¡£æ¡ˆå·¥å…· - é€šè¿‡BackendClientè°ƒç”¨Laravel API
            if tool_name == "get_user_profile":
                user_id = params.get("user_id")
                if not user_id:
                    return {"error": "user_id is required"}

                # ä»paramsä¸­æ£€æŸ¥æ˜¯å¦æœ‰é¢„åŠ è½½çš„ç”¨æˆ·æ¡£æ¡ˆ
                preloaded_profile = params.get("preloaded_user_profile")
                if preloaded_profile:
                    logger.info(f"âœ“ Using preloaded user profile for user_id={user_id}")
                    # ç¡®ä¿è¿”å›å¯åºåˆ—åŒ–çš„å­—å…¸æ ¼å¼
                    if hasattr(preloaded_profile, 'to_dict'):
                        return preloaded_profile.to_dict()
                    elif isinstance(preloaded_profile, dict):
                        return preloaded_profile
                    else:
                        # å¦‚æœæ˜¯å…¶ä»–ç±»å‹ï¼Œå°è¯•è½¬æ¢ä¸ºå­—å…¸
                        return {
                            "user_id": getattr(preloaded_profile, 'user_id', str(user_id)),
                            "basic_info": getattr(preloaded_profile, 'basic_info', {}),
                            "nutrition_profile": getattr(preloaded_profile, 'nutrition_profile', {}),
                            "fitness_config": getattr(preloaded_profile, 'fitness_config', {}),
                            "fitness_goals": getattr(preloaded_profile, 'fitness_goals', {}),
                            "strength_levels": getattr(preloaded_profile, 'strength_levels', {}),
                            "health_profile": getattr(preloaded_profile, 'health_profile', {}),
                            "created_at": getattr(preloaded_profile, 'created_at', None),
                            "updated_at": getattr(preloaded_profile, 'updated_at', None),
                        }

                # é€šè¿‡æ³¨å…¥çš„ç”¨æˆ·æ¡£æ¡ˆè·å–å™¨è·å–ç”¨æˆ·æ¡£æ¡ˆ
                # Frameworkå±‚ä¸åº”ç›´æ¥ä¾èµ–BackendClientï¼Œåº”ç”±åº”ç”¨å±‚æ³¨å…¥ç”¨æˆ·æ¡£æ¡ˆè·å–å™¨
                if hasattr(self, 'user_profile_provider') and self.user_profile_provider:
                    try:
                        profile = await self.user_profile_provider(user_id)
                        return profile
                    except Exception as e:
                        logger.warning(f"User profile provider failed: {e}")

                # è¿”å›åŸºç¡€ç”¨æˆ·ä¿¡æ¯ï¼Œé¿å…ç¡¬ç¼–ç ä¾èµ–
                return {
                    "user_id": str(user_id),
                    "note": "No user profile provider available in Framework layer",
                    "fallback_mode": True
                }

            # 2. GraphRAGæŸ¥è¯¢å·¥å…· - ç›´æ¥è°ƒç”¨GraphRAG
            elif tool_name == "query_knowledge_graph":
                try:
                    from framework.retrieval.graphrag import GraphRAGQueryTool
                    from framework.retrieval.graph.kg_full import KnowledgeGraphFull
                    import os

                    # åˆå§‹åŒ–KnowledgeGraphFull
                    neo4j_uri = os.getenv('NEO4J_URI', 'bolt://neo4j:7687')
                    neo4j_user = os.getenv('NEO4J_USER', 'neo4j')
                    neo4j_password = os.getenv('NEO4J_PASSWORD', 'build_body_2024')
                    qdrant_host = os.getenv('QDRANT_HOST', 'qdrant')
                    qdrant_port = int(os.getenv('QDRANT_PORT', '6333'))

                    kg_full = KnowledgeGraphFull(
                        neo4j_uri=neo4j_uri,
                        neo4j_user=neo4j_user,
                        neo4j_password=neo4j_password,
                        qdrant_host=qdrant_host,
                        qdrant_port=qdrant_port,
                        qdrant_collection="training_knowledge",
                        vector_size=1024,  # ä½¿ç”¨BGE-M3
                        embedding_model="BAAI/bge-m3"  # æŒ‡å®šBGE-M3æ¨¡å‹
                    )

                    # åˆ›å»ºGraphRAGæŸ¥è¯¢å·¥å…·
                    graphrag_tool = GraphRAGQueryTool(kg_full)

                    # æ‰§è¡ŒæŸ¥è¯¢
                    query_args = {
                        "query_type": params.get("query_type", "hybrid"),
                        "domain": params.get("domain", "fitness_exercises"),
                        "query_text": params.get("query_text", ""),
                        "filters": params.get("filters", {}),
                        "top_k": params.get("top_k", 10),
                        "min_similarity": params.get("min_similarity", 0.5),
                        "return_reason": params.get("return_reason", True)
                    }

                    result = await graphrag_tool.query(query_args)
                    return result

                except Exception as e:
                    logger.error(f"GraphRAG query failed: {e}")
                    return {
                        "tool": tool_name,
                        "query_text": params.get("query_text", ""),
                        "results": [],
                        "error": f"GraphRAG integration failed: {e}"
                    }

            # 3. å¥èº«å·¥å…· - è¿”å›æ¨¡æ‹Ÿç»“æœï¼ˆæœªæ¥å¯ä»¥è°ƒç”¨å®é™…çš„HTTP APIï¼‰
            elif tool_name in [
                "search-exercises-semantic", "get_exercise_details", "recommend_exercises_for_goal",
                "get_exercise_alternatives", "get_contraindicated_exercises",
                "suggest_safe_alternatives", "calculate_training_weight", "recommend_rpe_range",
                "get_training_program_template", "analyze_nutrition_intake",
                "get_disease_nutrition_advice", "recommend_training_volume",
                "evaluate_strength_level", "suggest_periodization_model",
                "design_training_split", "assess_injury_risk",
                "calculate_volume_reduction", "calculate_tdee_nutrition",
                "recommend_foods_by_goal", "design_meal_plan",
                "design_personalized_program", "design_personalized_program_v2",
                "adapt_program_for_injury",
                # æ–°å¢12ä¸ªä¸“ä¸šMCPå·¥å…· (Phase 1-5)
                "intelligent_exercise_selector", "exercise_similarity_finder", "safe_exercise_modifier",
                "periodized_program_designer", "muscle_group_volume_calculator", "movement_pattern_balancer",
                "injury_risk_assessor", "contraindications_checker",
                "exercise_nutrition_optimization", "muscle_recovery_nutrition",
                "training_analytics_dashboard", "evidence_based_recommender"
            ]:
                logger.info(f"ğŸ“ Local implementation for fitness tool: {tool_name}")

                # æ ¹æ®å·¥å…·ç±»å‹è¿”å›ç›¸åº”çš„æ¨¡æ‹Ÿç»“æœ
                if tool_name == "search-exercises-semantic":
                    return {
                        "tool": tool_name,
                        "query": params.get("query", ""),
                        "muscle_group": params.get("muscle_group", ""),
                        "equipment_type": params.get("equipment_type", ""),
                        "results": [
                            {
                                "id": "0001",
                                "name": "æ é“ƒå§æ¨",
                                "muscle_group": "èƒ¸éƒ¨",
                                "equipment": "æ é“ƒ",
                                "difficulty": "ä¸­çº§"
                            }
                        ],
                        "count": 1
                    }

                elif tool_name == "design_personalized_program_v2":
                    return {
                        "tool": tool_name,
                        "name": f"{params.get('training_level', 'Intermediate')} {params.get('goal', 'Muscle Gain')} Plan",
                        "description": f"ä¸ºç”¨æˆ· {params.get('user_id', 'unknown')} å®šåˆ¶çš„{params.get('training_frequency', 4)}å¤©/å‘¨è®­ç»ƒè®¡åˆ’",
                        "goal": params.get('goal', 'muscle_gain'),
                        "difficulty_level": params.get('training_level', 'intermediate'),
                        "duration_weeks": 12,
                        "frequency_per_week": params.get('training_frequency', 4),
                        "phases": [
                            {
                                "phase_index": 0,
                                "name": "åŸºç¡€é€‚åº”æœŸ",
                                "description": "å»ºç«‹åŸºç¡€åŠ›é‡å’ŒåŠ¨ä½œæ¨¡å¼",
                                "weeks": 4,
                                "intensity_range": "60-70% 1RM",
                                "volume_range": "ä¸­ç­‰",
                                "workouts": [
                                    {
                                        "workout_index": 0,
                                        "week_number": 1,
                                        "day_name": "è®­ç»ƒæ—¥1 - ä¸Šè‚¢æ¨",
                                        "focus": "èƒ¸éƒ¨å’Œä¸‰å¤´è‚Œ",
                                        "estimated_duration": params.get('session_duration', 60),
                                        "exercises": [
                                            {
                                                "exercise_id": "0001",
                                                "exercise_name": "æ é“ƒå§æ¨",
                                                "sets": 3,
                                                "reps": 10,
                                                "target_weight": 0,
                                                "rest_seconds": 90,
                                                "order": 1
                                            }
                                        ],
                                        "status": "pending"
                                    }
                                ]
                            }
                        ],
                        "equipment_needed": params.get('equipment_access', ['æ é“ƒ', 'å“‘é“ƒ'])
                    }

                # ========== å·¥å…·æ³¨å†Œæœºåˆ¶ ==========
                # Frameworkå±‚é€šè¿‡å·¥å…·æ³¨å†Œå™¨å¤„ç†é¢†åŸŸç‰¹å®šå·¥å…·
                # ç”±åº”ç”¨å±‚æ³¨å†Œå·¥å…·ï¼Œä¿æŒFrameworkå±‚é¢†åŸŸæ— å…³æ€§
                if hasattr(self, 'tool_registry') and self.tool_registry:
                    try:
                        tool_func = self.tool_registry.get_tool(tool_name)
                        if tool_func:
                            result = await tool_func(params)
                            return result
                    except Exception as e:
                        logger.error(f"Tool '{tool_name}' failed: {e}")
                        return {"tool": tool_name, "status": "error", "error": str(e)}

                # å¦‚æœå·¥å…·æœªæ³¨å†Œï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
                logger.warning(f"Tool '{tool_name}' not registered in framework")
                return {
                    "tool": tool_name,
                    "status": "not_found",
                    "error": f"Tool '{tool_name}' is not registered. Please register tools at application layer."
                }

        except Exception as e:
            logger.error(f"Local implementation failed: {tool_name}, error={e}")
            raise RuntimeError(f"Local implementation of '{tool_name}' failed: {e}")

    def get_execution_summary(self, tasks: List[Task]) -> Dict:
        """
        è·å–æ‰§è¡Œæ‘˜è¦
        
        Args:
            tasks: ä»»åŠ¡åˆ—è¡¨
        
        Returns:
            Dict: æ‰§è¡Œæ‘˜è¦
                {
                    "total": 10,
                    "completed": 8,
                    "failed": 1,
                    "skipped": 1,
                    "avg_duration": 0.25,
                    "total_duration": 2.5,
                    "parallel_efficiency": 0.75
                }
        
        Example:
            >>> summary = orchestrator.get_execution_summary(tasks)
            >>> print(f"æˆåŠŸç‡: {summary['completed'] / summary['total']:.1%}")
        """
        total = len(tasks)
        completed = sum(1 for t in tasks if t.status == TaskStatus.COMPLETED)
        failed = sum(1 for t in tasks if t.status == TaskStatus.FAILED)
        skipped = sum(1 for t in tasks if t.status == TaskStatus.SKIPPED)
        
        # è®¡ç®—æ‰§è¡Œæ—¶é•¿
        durations = [
            t.end_time - t.start_time
            for t in tasks
            if t.start_time and t.end_time
        ]
        
        avg_duration = sum(durations) / len(durations) if durations else 0
        
        # æ€»æ—¶é•¿ï¼ˆä»æœ€æ—©å¼€å§‹åˆ°æœ€æ™šç»“æŸï¼‰
        start_times = [t.start_time for t in tasks if t.start_time]
        end_times = [t.end_time for t in tasks if t.end_time]
        
        total_duration = (
            max(end_times) - min(start_times)
            if start_times and end_times
            else 0
        )
        
        # å¹¶è¡Œæ•ˆç‡ = ç†è®ºæ—¶é•¿ / å®é™…æ—¶é•¿
        theoretical_duration = sum(durations)
        parallel_efficiency = (
            theoretical_duration / total_duration
            if total_duration > 0
            else 0
        )
        
        return {
            "total": total,
            "completed": completed,
            "failed": failed,
            "skipped": skipped,
            "avg_duration": avg_duration,
            "total_duration": total_duration,
            "parallel_efficiency": parallel_efficiency
        }

