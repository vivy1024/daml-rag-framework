# -*- coding: utf-8 -*-
"""
DAGå¯è§†åŒ–å™¨ v1.0 - å·¥ä½œæµç¨‹å¯è§†åŒ–å’Œè°ƒè¯•

æä¾›DAGç»“æ„çš„å¯è§†åŒ–è¡¨ç¤ºã€æ‰§è¡Œæ—¥å¿—è¾“å‡ºå’Œè°ƒè¯•æ¨¡å¼æ”¯æŒã€‚
å¸®åŠ©å¼€å‘è€…ç†è§£æ‰§è¡Œè¿‡ç¨‹å’Œæ’æŸ¥é—®é¢˜ã€‚

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. DAGç»“æ„å¯è§†åŒ–ï¼ˆASCIIå›¾ã€Mermaidå›¾ï¼‰
2. æ‰§è¡Œæ—¥å¿—è¾“å‡ºï¼ˆè¯¦ç»†çš„å·¥å…·æ‰§è¡Œä¿¡æ¯ï¼‰
3. è°ƒè¯•æ¨¡å¼ï¼ˆä¸­é—´ç»“æœã€å†³ç­–è¿‡ç¨‹ï¼‰
4. æ‰§è¡Œå†å²æŸ¥è¯¢

ä½œè€…: BUILD_BODY Team
ç‰ˆæœ¬: v1.0.0
æ—¥æœŸ: 2025-12-12
"""

import logging
import json
import time
from typing import Dict, List, Optional, Any, Set
from dataclasses import dataclass, field
from enum import Enum
from datetime import datetime

logger = logging.getLogger(__name__)


class VisualizationFormat(Enum):
    """å¯è§†åŒ–æ ¼å¼"""
    ASCII = "ascii"           # ASCIIè‰ºæœ¯å›¾
    MERMAID = "mermaid"       # Mermaidæµç¨‹å›¾
    JSON = "json"             # JSONç»“æ„
    TREE = "tree"             # æ ‘å½¢ç»“æ„


class LogLevel(Enum):
    """æ—¥å¿—çº§åˆ«"""
    MINIMAL = 1      # æœ€å°æ—¥å¿—ï¼ˆä»…å…³é”®ä¿¡æ¯ï¼‰
    NORMAL = 2       # æ­£å¸¸æ—¥å¿—ï¼ˆæ ‡å‡†æ‰§è¡Œä¿¡æ¯ï¼‰
    DETAILED = 3     # è¯¦ç»†æ—¥å¿—ï¼ˆåŒ…å«å‚æ•°å’Œç»“æœï¼‰
    DEBUG = 4        # è°ƒè¯•æ—¥å¿—ï¼ˆæ‰€æœ‰ä¸­é—´ç»“æœå’Œå†³ç­–è¿‡ç¨‹ï¼‰


@dataclass
class ExecutionLogEntry:
    """æ‰§è¡Œæ—¥å¿—æ¡ç›®"""
    timestamp: float
    level: str
    tool_name: str
    status: str
    message: str
    details: Optional[Dict[str, Any]] = None
    duration: Optional[float] = None
    error: Optional[str] = None


@dataclass
class DAGVisualizationResult:
    """DAGå¯è§†åŒ–ç»“æœ"""
    format: str
    content: str
    metadata: Dict[str, Any] = field(default_factory=dict)


class DAGVisualizer:
    """DAGå¯è§†åŒ–å™¨"""
    
    def __init__(self, debug_mode: bool = False, log_level: LogLevel = LogLevel.NORMAL):
        """
        åˆå§‹åŒ–DAGå¯è§†åŒ–å™¨
        
        Args:
            debug_mode: æ˜¯å¦å¯ç”¨è°ƒè¯•æ¨¡å¼
            log_level: æ—¥å¿—çº§åˆ«
        """
        self.debug_mode = debug_mode
        self.log_level = log_level
        self.execution_logs: List[ExecutionLogEntry] = []
        
        logger.info(f"âœ… DAGå¯è§†åŒ–å™¨åˆå§‹åŒ–å®Œæˆ (è°ƒè¯•æ¨¡å¼: {debug_mode}, æ—¥å¿—çº§åˆ«: {log_level.name})")
    
    def visualize_dag_structure(
        self,
        template_name: str,
        tools: List[str],
        dependencies: Dict[str, List[str]],
        parallel_groups: Optional[List[List[str]]] = None,
        format: VisualizationFormat = VisualizationFormat.ASCII
    ) -> DAGVisualizationResult:
        """
        å¯è§†åŒ–DAGç»“æ„
        
        Args:
            template_name: æ¨¡æ¿åç§°
            tools: å·¥å…·åˆ—è¡¨
            dependencies: ä¾èµ–å…³ç³»
            parallel_groups: å¹¶è¡Œç»„
            format: å¯è§†åŒ–æ ¼å¼
            
        Returns:
            DAGVisualizationResult: å¯è§†åŒ–ç»“æœ
        """
        if format == VisualizationFormat.ASCII:
            content = self._generate_ascii_dag(template_name, tools, dependencies, parallel_groups)
        elif format == VisualizationFormat.MERMAID:
            content = self._generate_mermaid_dag(template_name, tools, dependencies)
        elif format == VisualizationFormat.JSON:
            content = self._generate_json_dag(template_name, tools, dependencies, parallel_groups)
        elif format == VisualizationFormat.TREE:
            content = self._generate_tree_dag(template_name, tools, dependencies)
        else:
            content = "ä¸æ”¯æŒçš„å¯è§†åŒ–æ ¼å¼"
        
        return DAGVisualizationResult(
            format=format.value,
            content=content,
            metadata={
                "template_name": template_name,
                "total_tools": len(tools),
                "total_dependencies": sum(len(deps) for deps in dependencies.values()),
                "parallel_groups_count": len(parallel_groups) if parallel_groups else 0
            }
        )
    
    def _generate_ascii_dag(
        self,
        template_name: str,
        tools: List[str],
        dependencies: Dict[str, List[str]],
        parallel_groups: Optional[List[List[str]]] = None
    ) -> str:
        """ç”ŸæˆASCIIè‰ºæœ¯å›¾"""
        lines = []
        lines.append("=" * 80)
        lines.append(f"DAGç»“æ„å¯è§†åŒ–: {template_name}")
        lines.append("=" * 80)
        lines.append("")
        
        # è®¡ç®—å±‚çº§
        levels = self._calculate_levels(tools, dependencies)
        
        # æŒ‰å±‚çº§è¾“å‡º
        for level_num, level_tools in enumerate(levels):
            lines.append(f"å±‚çº§ {level_num + 1}:")
            lines.append("â”€" * 40)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å¹¶è¡Œç»„
            is_parallel = self._is_parallel_level(level_tools, parallel_groups)
            
            if is_parallel:
                lines.append("  [å¹¶è¡Œæ‰§è¡Œ]")
            
            for tool in level_tools:
                # æ˜¾ç¤ºå·¥å…·åç§°
                tool_display = f"  â”Œâ”€ {tool}"
                lines.append(tool_display)
                
                # æ˜¾ç¤ºä¾èµ–
                deps = dependencies.get(tool, [])
                if deps:
                    lines.append(f"  â”‚  ä¾èµ–: {', '.join(deps)}")
                
                lines.append("  â””â”€")
            
            lines.append("")
        
        # ç»Ÿè®¡ä¿¡æ¯
        lines.append("=" * 80)
        lines.append("ç»Ÿè®¡ä¿¡æ¯:")
        lines.append(f"  æ€»å·¥å…·æ•°: {len(tools)}")
        lines.append(f"  æ€»å±‚çº§æ•°: {len(levels)}")
        lines.append(f"  æ€»ä¾èµ–æ•°: {sum(len(deps) for deps in dependencies.values())}")
        if parallel_groups:
            lines.append(f"  å¹¶è¡Œç»„æ•°: {len(parallel_groups)}")
        lines.append("=" * 80)
        
        return "\n".join(lines)
    
    def _generate_mermaid_dag(
        self,
        template_name: str,
        tools: List[str],
        dependencies: Dict[str, List[str]]
    ) -> str:
        """ç”ŸæˆMermaidæµç¨‹å›¾"""
        lines = []
        lines.append("```mermaid")
        lines.append("graph TD")
        lines.append(f"    Start([å¼€å§‹: {template_name}])")
        lines.append("")
        
        # æ·»åŠ èŠ‚ç‚¹
        for tool in tools:
            # è½¬æ¢å·¥å…·åä¸ºåˆæ³•çš„èŠ‚ç‚¹ID
            node_id = tool.replace("-", "_").replace(" ", "_")
            lines.append(f"    {node_id}[{tool}]")
        
        lines.append("")
        
        # æ·»åŠ èµ·å§‹è¿æ¥
        first_level_tools = [tool for tool in tools if not dependencies.get(tool, [])]
        for tool in first_level_tools:
            node_id = tool.replace("-", "_").replace(" ", "_")
            lines.append(f"    Start --> {node_id}")
        
        # æ·»åŠ ä¾èµ–å…³ç³»
        for tool, deps in dependencies.items():
            tool_id = tool.replace("-", "_").replace(" ", "_")
            for dep in deps:
                dep_id = dep.replace("-", "_").replace(" ", "_")
                lines.append(f"    {dep_id} --> {tool_id}")
        
        # æ·»åŠ ç»“æŸèŠ‚ç‚¹
        last_level_tools = self._find_last_level_tools(tools, dependencies)
        lines.append("")
        lines.append("    End([ç»“æŸ])")
        for tool in last_level_tools:
            node_id = tool.replace("-", "_").replace(" ", "_")
            lines.append(f"    {node_id} --> End")
        
        lines.append("```")
        
        return "\n".join(lines)
    
    def _generate_json_dag(
        self,
        template_name: str,
        tools: List[str],
        dependencies: Dict[str, List[str]],
        parallel_groups: Optional[List[List[str]]] = None
    ) -> str:
        """ç”ŸæˆJSONç»“æ„"""
        dag_structure = {
            "template_name": template_name,
            "tools": tools,
            "dependencies": dependencies,
            "parallel_groups": parallel_groups or [],
            "levels": self._calculate_levels(tools, dependencies),
            "statistics": {
                "total_tools": len(tools),
                "total_dependencies": sum(len(deps) for deps in dependencies.values()),
                "total_levels": len(self._calculate_levels(tools, dependencies)),
                "parallel_groups_count": len(parallel_groups) if parallel_groups else 0
            }
        }
        
        return json.dumps(dag_structure, indent=2, ensure_ascii=False)
    
    def _generate_tree_dag(
        self,
        template_name: str,
        tools: List[str],
        dependencies: Dict[str, List[str]]
    ) -> str:
        """ç”Ÿæˆæ ‘å½¢ç»“æ„"""
        lines = []
        lines.append(f"{template_name}")
        lines.append("â”‚")
        
        # æ‰¾åˆ°æ ¹èŠ‚ç‚¹ï¼ˆæ²¡æœ‰ä¾èµ–çš„å·¥å…·ï¼‰
        root_tools = [tool for tool in tools if not dependencies.get(tool, [])]
        
        # é€’å½’æ„å»ºæ ‘
        visited = set()
        for i, root in enumerate(root_tools):
            is_last = (i == len(root_tools) - 1)
            self._build_tree_recursive(root, dependencies, tools, lines, "", is_last, visited)
        
        return "\n".join(lines)
    
    def _build_tree_recursive(
        self,
        tool: str,
        dependencies: Dict[str, List[str]],
        all_tools: List[str],
        lines: List[str],
        prefix: str,
        is_last: bool,
        visited: Set[str]
    ):
        """é€’å½’æ„å»ºæ ‘å½¢ç»“æ„"""
        if tool in visited:
            return
        visited.add(tool)
        
        # å½“å‰èŠ‚ç‚¹
        connector = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
        lines.append(f"{prefix}{connector}{tool}")
        
        # æ‰¾åˆ°ä¾èµ–å½“å‰å·¥å…·çš„å­å·¥å…·
        children = [t for t in all_tools if tool in dependencies.get(t, [])]
        
        # é€’å½’å¤„ç†å­èŠ‚ç‚¹
        new_prefix = prefix + ("    " if is_last else "â”‚   ")
        for i, child in enumerate(children):
            child_is_last = (i == len(children) - 1)
            self._build_tree_recursive(child, dependencies, all_tools, lines, new_prefix, child_is_last, visited)
    
    def _calculate_levels(
        self,
        tools: List[str],
        dependencies: Dict[str, List[str]]
    ) -> List[List[str]]:
        """è®¡ç®—DAGå±‚çº§"""
        levels = []
        remaining_tools = set(tools)
        processed_tools = set()
        
        while remaining_tools:
            # æ‰¾åˆ°å½“å‰å¯ä»¥æ‰§è¡Œçš„å·¥å…·ï¼ˆä¾èµ–éƒ½å·²å¤„ç†ï¼‰
            current_level = []
            for tool in remaining_tools:
                deps = dependencies.get(tool, [])
                if all(dep in processed_tools for dep in deps):
                    current_level.append(tool)
            
            if not current_level:
                # æ£€æµ‹åˆ°å¾ªç¯ä¾èµ–
                logger.warning(f"âš ï¸ æ£€æµ‹åˆ°å¾ªç¯ä¾èµ–ï¼Œå‰©ä½™å·¥å…·: {remaining_tools}")
                break
            
            levels.append(current_level)
            remaining_tools -= set(current_level)
            processed_tools.update(current_level)
        
        return levels
    
    def _is_parallel_level(
        self,
        level_tools: List[str],
        parallel_groups: Optional[List[List[str]]] = None
    ) -> bool:
        """åˆ¤æ–­å±‚çº§æ˜¯å¦å¯å¹¶è¡Œæ‰§è¡Œ"""
        if not parallel_groups:
            return len(level_tools) > 1
        
        # æ£€æŸ¥æ˜¯å¦åœ¨å¹¶è¡Œç»„ä¸­
        for group in parallel_groups:
            if set(level_tools).issubset(set(group)):
                return True
        
        return False
    
    def _find_last_level_tools(
        self,
        tools: List[str],
        dependencies: Dict[str, List[str]]
    ) -> List[str]:
        """æ‰¾åˆ°æœ€åä¸€å±‚çš„å·¥å…·ï¼ˆæ²¡æœ‰å…¶ä»–å·¥å…·ä¾èµ–å®ƒä»¬ï¼‰"""
        depended_tools = set()
        for deps in dependencies.values():
            depended_tools.update(deps)
        
        return [tool for tool in tools if tool not in depended_tools]
    
    def log_tool_execution(
        self,
        tool_name: str,
        status: str,
        message: str,
        details: Optional[Dict[str, Any]] = None,
        duration: Optional[float] = None,
        error: Optional[str] = None
    ):
        """
        è®°å½•å·¥å…·æ‰§è¡Œæ—¥å¿—
        
        Args:
            tool_name: å·¥å…·åç§°
            status: æ‰§è¡ŒçŠ¶æ€
            message: æ—¥å¿—æ¶ˆæ¯
            details: è¯¦ç»†ä¿¡æ¯
            duration: æ‰§è¡Œæ—¶é•¿
            error: é”™è¯¯ä¿¡æ¯
        """
        # æ ¹æ®æ—¥å¿—çº§åˆ«å†³å®šæ˜¯å¦è®°å½•
        if self.log_level == LogLevel.MINIMAL and status not in ["failed", "completed"]:
            return
        
        entry = ExecutionLogEntry(
            timestamp=time.time(),
            level=self._get_log_level_for_status(status),
            tool_name=tool_name,
            status=status,
            message=message,
            details=details if self.log_level.value >= LogLevel.DETAILED.value else None,
            duration=duration,
            error=error
        )
        
        self.execution_logs.append(entry)
        
        # è¾“å‡ºæ—¥å¿—
        self._print_log_entry(entry)
    
    def _get_log_level_for_status(self, status: str) -> str:
        """æ ¹æ®çŠ¶æ€è·å–æ—¥å¿—çº§åˆ«"""
        status_map = {
            "pending": "INFO",
            "running": "INFO",
            "completed": "INFO",
            "failed": "ERROR",
            "skipped": "WARNING",
            "cancelled": "WARNING"
        }
        return status_map.get(status, "INFO")
    
    def _print_log_entry(self, entry: ExecutionLogEntry):
        """æ‰“å°æ—¥å¿—æ¡ç›®"""
        timestamp_str = datetime.fromtimestamp(entry.timestamp).strftime("%H:%M:%S.%f")[:-3]
        
        # çŠ¶æ€å›¾æ ‡
        status_icons = {
            "pending": "â³",
            "running": "ğŸ”„",
            "completed": "âœ…",
            "failed": "âŒ",
            "skipped": "â­ï¸",
            "cancelled": "ğŸš«"
        }
        icon = status_icons.get(entry.status, "ğŸ“")
        
        # åŸºæœ¬ä¿¡æ¯
        log_msg = f"[{timestamp_str}] {icon} {entry.tool_name}: {entry.message}"
        
        # æ·»åŠ æ—¶é•¿
        if entry.duration is not None:
            log_msg += f" ({entry.duration:.2f}s)"
        
        # è¾“å‡ºæ—¥å¿—
        if entry.level == "ERROR":
            logger.error(log_msg)
            if entry.error:
                logger.error(f"  é”™è¯¯è¯¦æƒ…: {entry.error}")
        elif entry.level == "WARNING":
            logger.warning(log_msg)
        else:
            logger.info(log_msg)
        
        # è¯¦ç»†ä¿¡æ¯ï¼ˆè°ƒè¯•æ¨¡å¼æˆ–è¯¦ç»†æ—¥å¿—ï¼‰
        if self.debug_mode or self.log_level.value >= LogLevel.DETAILED.value:
            if entry.details:
                logger.debug(f"  è¯¦ç»†ä¿¡æ¯: {json.dumps(entry.details, indent=2, ensure_ascii=False)}")
    
    def log_decision_process(
        self,
        stage: str,
        decision: str,
        reason: str,
        alternatives: Optional[List[str]] = None,
        confidence: Optional[float] = None
    ):
        """
        è®°å½•å†³ç­–è¿‡ç¨‹ï¼ˆè°ƒè¯•æ¨¡å¼ï¼‰
        
        Args:
            stage: å†³ç­–é˜¶æ®µ
            decision: å†³ç­–ç»“æœ
            reason: å†³ç­–ç†ç”±
            alternatives: å¤‡é€‰æ–¹æ¡ˆ
            confidence: ç½®ä¿¡åº¦
        """
        if not self.debug_mode:
            return
        
        logger.debug("=" * 60)
        logger.debug(f"ğŸ¤” å†³ç­–é˜¶æ®µ: {stage}")
        logger.debug(f"ğŸ“‹ å†³ç­–ç»“æœ: {decision}")
        logger.debug(f"ğŸ’¡ å†³ç­–ç†ç”±: {reason}")
        
        if confidence is not None:
            logger.debug(f"ğŸ¯ ç½®ä¿¡åº¦: {confidence:.2f}")
        
        if alternatives:
            logger.debug(f"ğŸ”„ å¤‡é€‰æ–¹æ¡ˆ: {', '.join(alternatives)}")
        
        logger.debug("=" * 60)
    
    def log_intermediate_result(
        self,
        stage: str,
        result_type: str,
        result_data: Any
    ):
        """
        è®°å½•ä¸­é—´ç»“æœï¼ˆè°ƒè¯•æ¨¡å¼ï¼‰
        
        Args:
            stage: æ‰§è¡Œé˜¶æ®µ
            result_type: ç»“æœç±»å‹
            result_data: ç»“æœæ•°æ®
        """
        if not self.debug_mode:
            return
        
        logger.debug(f"ğŸ“Š ä¸­é—´ç»“æœ [{stage}] - {result_type}:")
        
        if isinstance(result_data, (dict, list)):
            logger.debug(json.dumps(result_data, indent=2, ensure_ascii=False))
        else:
            logger.debug(str(result_data))
    
    def get_execution_logs(
        self,
        tool_name: Optional[str] = None,
        status: Optional[str] = None,
        limit: Optional[int] = None
    ) -> List[ExecutionLogEntry]:
        """
        è·å–æ‰§è¡Œæ—¥å¿—
        
        Args:
            tool_name: è¿‡æ»¤å·¥å…·åç§°
            status: è¿‡æ»¤çŠ¶æ€
            limit: é™åˆ¶æ•°é‡
            
        Returns:
            List[ExecutionLogEntry]: æ—¥å¿—åˆ—è¡¨
        """
        logs = self.execution_logs
        
        # è¿‡æ»¤
        if tool_name:
            logs = [log for log in logs if log.tool_name == tool_name]
        
        if status:
            logs = [log for log in logs if log.status == status]
        
        # é™åˆ¶æ•°é‡
        if limit:
            logs = logs[-limit:]
        
        return logs
    
    def generate_execution_summary(self) -> str:
        """ç”Ÿæˆæ‰§è¡Œæ‘˜è¦"""
        if not self.execution_logs:
            return "æš‚æ— æ‰§è¡Œæ—¥å¿—"
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_logs = len(self.execution_logs)
        status_counts = {}
        tool_counts = {}
        total_duration = 0.0
        
        for log in self.execution_logs:
            # çŠ¶æ€ç»Ÿè®¡
            status_counts[log.status] = status_counts.get(log.status, 0) + 1
            
            # å·¥å…·ç»Ÿè®¡
            tool_counts[log.tool_name] = tool_counts.get(log.tool_name, 0) + 1
            
            # æ—¶é•¿ç»Ÿè®¡
            if log.duration:
                total_duration += log.duration
        
        # ç”Ÿæˆæ‘˜è¦
        lines = []
        lines.append("=" * 80)
        lines.append("æ‰§è¡Œæ‘˜è¦")
        lines.append("=" * 80)
        lines.append("")
        lines.append(f"æ€»æ—¥å¿—æ•°: {total_logs}")
        lines.append(f"æ€»æ‰§è¡Œæ—¶é•¿: {total_duration:.2f}s")
        lines.append("")
        lines.append("çŠ¶æ€ç»Ÿè®¡:")
        for status, count in sorted(status_counts.items()):
            lines.append(f"  {status}: {count}")
        lines.append("")
        lines.append("å·¥å…·ç»Ÿè®¡:")
        for tool, count in sorted(tool_counts.items(), key=lambda x: x[1], reverse=True):
            lines.append(f"  {tool}: {count}æ¬¡")
        lines.append("=" * 80)
        
        return "\n".join(lines)
    
    def clear_logs(self):
        """æ¸…ç©ºæ—¥å¿—"""
        self.execution_logs.clear()
        logger.info("ğŸ—‘ï¸ æ‰§è¡Œæ—¥å¿—å·²æ¸…ç©º")
    
    def export_logs_to_file(self, filepath: str):
        """
        å¯¼å‡ºæ—¥å¿—åˆ°æ–‡ä»¶
        
        Args:
            filepath: æ–‡ä»¶è·¯å¾„
        """
        try:
            logs_data = []
            for log in self.execution_logs:
                logs_data.append({
                    "timestamp": log.timestamp,
                    "datetime": datetime.fromtimestamp(log.timestamp).isoformat(),
                    "level": log.level,
                    "tool_name": log.tool_name,
                    "status": log.status,
                    "message": log.message,
                    "details": log.details,
                    "duration": log.duration,
                    "error": log.error
                })
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(logs_data, f, indent=2, ensure_ascii=False)
            
            logger.info(f"âœ… æ—¥å¿—å·²å¯¼å‡ºåˆ°: {filepath}")
        
        except Exception as e:
            logger.error(f"âŒ å¯¼å‡ºæ—¥å¿—å¤±è´¥: {e}")


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»ºå¯è§†åŒ–å™¨
    visualizer = DAGVisualizer(debug_mode=True, log_level=LogLevel.DEBUG)
    
    # ç¤ºä¾‹DAGç»“æ„
    template_name = "å®Œæ•´è®­ç»ƒè®¡åˆ’"
    tools = [
        "get_user_profile",
        "contraindications_checker",
        "injury_risk_assessor",
        "intelligent_exercise_selector",
        "muscle_group_volume_calculator",
        "professional_program_designer"
    ]
    dependencies = {
        "get_user_profile": [],
        "contraindications_checker": ["get_user_profile"],
        "injury_risk_assessor": ["get_user_profile"],
        "intelligent_exercise_selector": ["contraindications_checker", "injury_risk_assessor"],
        "muscle_group_volume_calculator": ["get_user_profile"],
        "professional_program_designer": ["intelligent_exercise_selector", "muscle_group_volume_calculator"]
    }
    parallel_groups = [
        ["get_user_profile"],
        ["contraindications_checker", "injury_risk_assessor", "muscle_group_volume_calculator"],
        ["intelligent_exercise_selector"],
        ["professional_program_designer"]
    ]
    
    # æµ‹è¯•ASCIIå¯è§†åŒ–
    print("\n" + "=" * 80)
    print("æµ‹è¯•1: ASCIIå¯è§†åŒ–")
    print("=" * 80)
    result = visualizer.visualize_dag_structure(
        template_name, tools, dependencies, parallel_groups, VisualizationFormat.ASCII
    )
    print(result.content)
    
    # æµ‹è¯•Mermaidå¯è§†åŒ–
    print("\n" + "=" * 80)
    print("æµ‹è¯•2: Mermaidå¯è§†åŒ–")
    print("=" * 80)
    result = visualizer.visualize_dag_structure(
        template_name, tools, dependencies, parallel_groups, VisualizationFormat.MERMAID
    )
    print(result.content)
    
    # æµ‹è¯•æ‰§è¡Œæ—¥å¿—
    print("\n" + "=" * 80)
    print("æµ‹è¯•3: æ‰§è¡Œæ—¥å¿—")
    print("=" * 80)
    visualizer.log_tool_execution("get_user_profile", "running", "å¼€å§‹è·å–ç”¨æˆ·æ¡£æ¡ˆ")
    visualizer.log_tool_execution("get_user_profile", "completed", "ç”¨æˆ·æ¡£æ¡ˆè·å–æˆåŠŸ", duration=0.5)
    visualizer.log_tool_execution("contraindications_checker", "running", "å¼€å§‹æ£€æŸ¥ç¦å¿ŒåŠ¨ä½œ")
    visualizer.log_tool_execution("contraindications_checker", "completed", "ç¦å¿Œæ£€æŸ¥å®Œæˆ", duration=1.2)
    
    # æµ‹è¯•å†³ç­–è¿‡ç¨‹
    print("\n" + "=" * 80)
    print("æµ‹è¯•4: å†³ç­–è¿‡ç¨‹")
    print("=" * 80)
    visualizer.log_decision_process(
        stage="DAGé€‰æ‹©",
        decision="complete_training_plan",
        reason="ç”¨æˆ·éœ€è¦å®Œæ•´çš„å¢è‚Œè®­ç»ƒè®¡åˆ’",
        alternatives=["nutrition_plan", "exercise_selection"],
        confidence=0.95
    )
    
    # æµ‹è¯•æ‰§è¡Œæ‘˜è¦
    print("\n" + "=" * 80)
    print("æµ‹è¯•5: æ‰§è¡Œæ‘˜è¦")
    print("=" * 80)
    print(visualizer.generate_execution_summary())
