# DAML-RAG Framework

**Domain-Adaptive Meta-Learning RAG** - Production-Ready Framework for Vertical Domain AI Applications  
**é¢†åŸŸè‡ªé€‚åº”å…ƒå­¦ä¹ RAGæ¡†æ¶** - é¢å‘å‚ç›´é¢†åŸŸAIåº”ç”¨çš„ç”Ÿäº§å°±ç»ªæ¡†æ¶

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![License](https://img.shields.io/badge/License-Apache%202.0-green.svg)](LICENSE)
[![Version](https://img.shields.io/badge/Version-1.0.0-orange.svg)](CHANGELOG.md)
[![Paper](https://img.shields.io/badge/Paper-arXiv-red.svg)](#)

> ğŸ“ **Combining GraphRAG, In-Context Learning, Multi-Agent Orchestration for Cost-Effective Vertical Domain AI**  
> ğŸš€ **ç»“åˆGraphRAGã€ä¸Šä¸‹æ–‡å­¦ä¹ ã€å¤šæ™ºèƒ½ä½“ååŒï¼Œæ‰“é€ æˆæœ¬é«˜æ•ˆçš„å‚ç›´é¢†åŸŸAIç³»ç»Ÿ**

## ğŸ“– Overview / æ¦‚è§ˆ

DAML-RAG is a production-ready framework that integrates proven techniquesâ€”GraphRAG hybrid retrieval, In-Context Learning, Teacher-Student collaboration, and MCP-based multi-agent orchestrationâ€”for building vertical domain AI applications with **85% token reduction** and **93% cost optimization**.

DAML-RAGæ˜¯ä¸€ä¸ªç”Ÿäº§å°±ç»ªæ¡†æ¶ï¼Œæ•´åˆäº†ç»è¿‡éªŒè¯çš„æŠ€æœ¯â€”â€”GraphRAGæ··åˆæ£€ç´¢ã€ä¸Šä¸‹æ–‡å­¦ä¹ ã€æ•™å¸ˆ-å­¦ç”ŸååŒå’ŒåŸºäºMCPçš„å¤šæ™ºèƒ½ä½“ç¼–æ’â€”â€”ç”¨äºæ„å»ºå‚ç›´é¢†åŸŸAIåº”ç”¨ï¼Œå®ç°**85%çš„TokenèŠ‚çœ**å’Œ**93%çš„æˆæœ¬ä¼˜åŒ–**ã€‚

**NOT a new theory**, but an **engineering best practice** framework for practitioners.

**ä¸æ˜¯æ–°ç†è®º**ï¼Œè€Œæ˜¯é¢å‘å®è·µè€…çš„**å·¥ç¨‹æœ€ä½³å®è·µ**æ¡†æ¶ã€‚

---

## ğŸ”¬ Academic Positioning / å­¦æœ¯å®šä½

### What DAML-RAG IS âœ…

- **Engineering Framework**: Systematic integration of RAG [1], GraphRAG [2], ICL [3], Knowledge Graphs [4]
- **Production System**: Validated in BUILD_BODY fitness domain (1000+ daily queries)
- **Cost Optimization**: Teacher-student collaboration achieving 93% cost reduction
- **Vertical Domain Focus**: Specialized for knowledge-intensive domains

### What DAML-RAG is NOT âŒ

- âŒ **NOT a new ML/AI theory**: No novel algorithms or learning paradigms
- âŒ **NOT claiming universal superiority**: Designed for specific use cases
- âŒ **NOT automated domain adaptation**: Requires domain expertise for knowledge graph construction
- âŒ **NOT inference-time "meta-learning"**: Correctly termed "In-Context Learning" (v2.0 correction)

**å·¥ç¨‹å®šä½**ï¼šå°†ç»è¿‡éªŒè¯çš„æŠ€æœ¯æ•´åˆä¸ºé¢å‘å‚ç›´é¢†åŸŸåº”ç”¨çš„ç”Ÿäº§å°±ç»ªç³»ç»Ÿã€‚

---

## ğŸ¯ Key Features / æ ¸å¿ƒç‰¹æ€§

- ğŸ¯ **GraphRAG Hybrid Retrieval**: Vector + Graph + Rules (85% token reduction)
- ğŸ§  **In-Context Learning** â­(v2.0 corrected): Quality maintenance via Few-Shot + Case-Based Reasoning
- âš¡ **Teacher-Student Model**: DeepSeek (teacher) + Ollama (student) (93% cost reduction)
- ğŸ”Œ **MCP Orchestration**: Standardized multi-agent collaboration via Model Context Protocol
- ğŸ›¡ï¸ **Quality Assurance**: Automatic quality monitoring and escalation
- ğŸ“Š **Production-Ready**: Complete monitoring, caching, fault tolerance

## ğŸ—ï¸ æ ¸å¿ƒæ¶æ„ï¼šä¸‰å±‚æ£€ç´¢ç³»ç»Ÿ

DAML-RAGçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºä¸‰å±‚æ··åˆæ£€ç´¢æ¶æ„ï¼Œå®Œç¾ç»“åˆå‘é‡æ£€ç´¢ã€çŸ¥è¯†å›¾è°±å’Œä¸šåŠ¡è§„åˆ™ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ç”¨æˆ·æŸ¥è¯¢è¾“å…¥                               â”‚
â”‚         "æ¨èä¸ä¼¤è†ç›–çš„è…¿éƒ¨å¢è‚ŒåŠ¨ä½œ"                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 1: å‘é‡è¯­ä¹‰æ£€ç´¢ (Vector Retrieval)                    â”‚
â”‚                                                              â”‚
â”‚  ğŸ“Š æ”¯æŒå¤šç§å‘é‡æ•°æ®åº“:                                        â”‚
â”‚    â€¢ Qdrant (æ¨è) - é«˜æ€§èƒ½å‘é‡æ•°æ®åº“                          â”‚
â”‚    â€¢ FAISS - Facebook AIç›¸ä¼¼åº¦æœç´¢                            â”‚
â”‚    â€¢ Milvus - å¼€æºå‘é‡æ•°æ®åº“                                  â”‚
â”‚    â€¢ Pinecone/Weaviate - äº‘ç«¯å‘é‡æœåŠ¡                        â”‚
â”‚                                                              â”‚
â”‚  ğŸ” è¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é…:                                          â”‚
â”‚    â€¢ Cosine Similarity (ä½™å¼¦ç›¸ä¼¼åº¦)                           â”‚
â”‚    â€¢ HNSWç´¢å¼•ä¼˜åŒ– (< 50mså“åº”æ—¶é—´)                            â”‚
â”‚    â€¢ å¤šè¯­è¨€embeddingæ¨¡å‹æ”¯æŒ                                 â”‚
â”‚                                                              â”‚
â”‚  ğŸ¯ æ ¸å¿ƒåŠŸèƒ½:                                               â”‚
â”‚    â€¢ ç†è§£ç”¨æˆ·æ„å›¾ ("å¢è‚Œ" = "è‚¥å¤§è®­ç»ƒ")                        â”‚
â”‚    â€¢ æ¨¡ç³ŠåŒ¹é… (æ‹¼å†™é”™è¯¯ã€åŒä¹‰è¯è¯†åˆ«)                           â”‚
â”‚    â€¢ å¿«é€Ÿå¬å›å€™é€‰é›† (Top 20-50)                              â”‚
â”‚    â€¢ å¤šæ¨¡æ€æ£€ç´¢æ”¯æŒ (æ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 2: å›¾å…³ç³»æ¨ç† (Knowledge Graph)                       â”‚
â”‚                                                              â”‚
â”‚  ğŸ•¸ï¸ æ”¯æŒå¤šç§å›¾æ•°æ®åº“:                                         â”‚
â”‚    â€¢ Neo4j (æ¨è) - ä¸“ä¸šå›¾æ•°æ®åº“                             â”‚
â”‚    â€¢ ArangoDB - å¤šæ¨¡å‹æ•°æ®åº“                                  â”‚
â”‚    â€¢ JanusGraph - åˆ†å¸ƒå¼å›¾æ•°æ®åº“                              â”‚
â”‚    â€¢ Amazon Neptune - äº‘ç«¯å›¾æœåŠ¡                             â”‚
â”‚                                                              â”‚
â”‚  ğŸ”— ç»“æ„åŒ–å…³ç³»æ¨ç†:                                          â”‚
â”‚    â€¢ CypheræŸ¥è¯¢è¯­è¨€ (Neo4j)                                  â”‚
â”‚    â€¢ Gremlinå›¾éå†è¯­è¨€                                       â”‚
â”‚    â€¢ SPARQLè¯­ä¹‰æŸ¥è¯¢                                          â”‚
â”‚    â€¢ å¤šè·³æ¨ç†èƒ½åŠ› (< 100ms)                                  â”‚
â”‚                                                              â”‚
â”‚  ğŸ¯ æ ¸å¿ƒåŠŸèƒ½:                                               â”‚
â”‚    â€¢ ç²¾ç¡®ç­›é€‰ (åŸºäº2,447+å®ä½“èŠ‚ç‚¹)                           â”‚
â”‚    â€¢ çº¦æŸéªŒè¯ ("ä¸å‹è¿«è†ç›–")                                 â”‚
â”‚    â€¢ å¯è§£é‡Šæ€§ (æ¸…æ™°çš„æ¨ç†è·¯å¾„)                                â”‚
â”‚    â€¢ å¤šè·³æ¨ç† ("åŠ¨ä½œâ†’è‚Œç¾¤â†’ç›®æ ‡â†’çº¦æŸ")                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 3: ä¸šåŠ¡è§„åˆ™éªŒè¯ (Rule Filtering)                      â”‚
â”‚                                                              â”‚
â”‚  ğŸ“‹ é¢†åŸŸä¸“ä¸šè§„åˆ™å¼•æ“:                                          â”‚
â”‚    â€¢ å®‰å…¨è§„åˆ™ (å¹´é¾„ã€æŸä¼¤ã€åº·å¤é˜¶æ®µ)                           â”‚
â”‚    â€¢ å™¨æ¢°è§„åˆ™ (å¯ç”¨è®¾å¤‡ã€åœºåœ°é™åˆ¶)                             â”‚
â”‚    â€¢ å®¹é‡è§„åˆ™ (MRVã€è¶…é‡æ¢å¤ã€è®­ç»ƒé¢‘ç‡)                        â”‚
â”‚    â€¢ ä¸ªæ€§åŒ–è§„åˆ™ (ç”¨æˆ·åå¥½ã€ç›®æ ‡æ°´å¹³)                           â”‚
â”‚                                                              â”‚
â”‚  ğŸ›¡ï¸ æ™ºèƒ½éªŒè¯ç³»ç»Ÿ:                                           â”‚
â”‚    â€¢ åŠ¨æ€è§„åˆ™åŠ è½½ (< 20ms)                                   â”‚
â”‚    â€¢ è§„åˆ™ä¼˜å…ˆçº§ç®¡ç†                                          â”‚
â”‚    â€¢ è§„åˆ™å†²çªæ£€æµ‹å’Œè§£å†³                                      â”‚
â”‚    â€¢ è§„åˆ™æ•ˆæœè¯„ä¼°å’Œä¼˜åŒ–                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“Š æœ€ç»ˆç»“æœ: 5ä¸ªç²¾å‡†æ¨è + æ¨èç†ç”± + ç½®ä¿¡åº¦è¯„åˆ†                â”‚
â”‚  ğŸ’¡ Tokenä¼˜åŒ–: < 200 tokens (ç›¸æ¯”ä¼ ç»ŸRAGèŠ‚çœ85%)              â”‚
â”‚  âš¡ æ€»å“åº”æ—¶é—´: < 950ms                                      â”‚
â”‚  ğŸ¯ ç”¨æˆ·æ»¡æ„åº¦: 4.4/5 (æå‡38%)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”§ æŠ€æœ¯æ ˆé€‰å‹

DAML-RAGæ”¯æŒçµæ´»çš„æŠ€æœ¯æ ˆé€‰å‹ï¼Œå¼€å‘è€…å¯ä»¥æ ¹æ®åå¥½å’Œéœ€æ±‚é€‰æ‹©ï¼š

```yaml
# å‘é‡æ•°æ®åº“é€‰æ‹©
å‘é‡æ•°æ®åº“:
  Qdrant:      â­â­â­â­â­ æ¨è (é«˜æ€§èƒ½ã€æ˜“éƒ¨ç½²)
  FAISS:       â­â­â­â­   (æœ¬åœ°éƒ¨ç½²ã€é€Ÿåº¦å¿«)
  Milvus:      â­â­â­â­   (å¼€æºã€åˆ†å¸ƒå¼)
  Pinecone:    â­â­â­     (äº‘ç«¯ã€æ‰˜ç®¡æœåŠ¡)
  Weaviate:    â­â­â­     (è¯­ä¹‰æœç´¢ã€GraphQL)

# å›¾æ•°æ®åº“é€‰æ‹©
å›¾æ•°æ®åº“:
  Neo4j:       â­â­â­â­â­ æ¨è (ä¸“ä¸šå›¾æ•°æ®åº“)
  ArangoDB:    â­â­â­â­   (å¤šæ¨¡å‹ã€çµæ´»)
  JanusGraph:  â­â­â­     (åˆ†å¸ƒå¼ã€å¤§æ•°æ®)
  Neptune:     â­â­â­     (AWSé›†æˆ)

# AIæ¨¡å‹é€‰æ‹©
å¤§æ¨¡å‹:
  DeepSeek:    â­â­â­â­â­ æ•™å¸ˆæ¨¡å‹ (é«˜è´¨é‡ã€ä¸­æ–‡ä¼˜åŒ–)
  GPT-4:       â­â­â­â­   (é€šç”¨èƒ½åŠ›å¼º)
  Claude:      â­â­â­â­   (å®‰å…¨æ€§é«˜)
  Qwen:        â­â­â­â­   (å¼€æºã€ä¸­æ–‡)

å°æ¨¡å‹:
  Ollama:      â­â­â­â­â­ å­¦ç”Ÿæ¨¡å‹ (æœ¬åœ°éƒ¨ç½²ã€æˆæœ¬ä¼˜åŒ–)
  Llama:       â­â­â­â­   (å¼€æºã€æ€§èƒ½å¥½)
  Phi:         â­â­â­     (å¾®è½¯ã€å°è€Œç²¾)
  Gemma:       â­â­â­     (Googleã€è½»é‡çº§)
```

### ğŸ“¦ æ¨¡å—ç»“æ„

```
daml-rag-framework/
â”œâ”€â”€ daml-rag-core/              # ğŸ”§ æ ¸å¿ƒæ¡†æ¶
â”‚   â”œâ”€â”€ interfaces/             # æŠ½è±¡æ¥å£å®šä¹‰
â”‚   â”œâ”€â”€ models/                 # æ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ config/                 # é…ç½®ç®¡ç†
â”‚   â””â”€â”€ utils/                  # å·¥å…·å‡½æ•°
â”œâ”€â”€ daml-rag-retrieval/         # ğŸ” ä¸‰å±‚æ£€ç´¢å¼•æ“
â”‚   â”œâ”€â”€ vector/                 # å‘é‡æ£€ç´¢å±‚
â”‚   â”‚   â”œâ”€â”€ qdrant.py          # Qdrantå®ç°
â”‚   â”‚   â”œâ”€â”€ faiss.py           # FAISSå®ç°
â”‚   â”‚   â””â”€â”€ base.py            # æŠ½è±¡åŸºç±»
â”‚   â”œâ”€â”€ knowledge/              # çŸ¥è¯†å›¾è°±å±‚
â”‚   â”‚   â”œâ”€â”€ neo4j.py           # Neo4jå®ç°
â”‚   â”‚   â”œâ”€â”€ arangodb.py        # ArangoDBå®ç°
â”‚   â”‚   â””â”€â”€ base.py            # æŠ½è±¡åŸºç±»
â”‚   â”œâ”€â”€ rules/                  # è§„åˆ™è¿‡æ»¤å±‚
â”‚   â”‚   â”œâ”€â”€ engine.py          # è§„åˆ™å¼•æ“
â”‚   â”‚   â”œâ”€â”€ validators.py      # éªŒè¯å™¨
â”‚   â”‚   â””â”€â”€ domain_rules.py    # é¢†åŸŸè§„åˆ™
â”‚   â””â”€â”€ cache/                  # ç¼“å­˜ç®¡ç†
â”‚       â”œâ”€â”€ redis.py           # Redisç¼“å­˜
â”‚       â””â”€â”€ memory.py          # å†…å­˜ç¼“å­˜
â”œâ”€â”€ daml-rag-orchestration/     # ğŸ¯ ä»»åŠ¡ç¼–æ’å¼•æ“
â”‚   â”œâ”€â”€ orchestrator.py        # ç¼–æ’å™¨
â”‚   â”œâ”€â”€ dag.py                  # DAGç®¡ç†
â”‚   â”œâ”€â”€ scheduler.py            # ä»»åŠ¡è°ƒåº¦
â”‚   â””â”€â”€ mcp_tools.py           # MCPå·¥å…·é›†æˆ
â”œâ”€â”€ daml-rag-learning/          # ğŸ§  æ¨ç†æ—¶å­¦ä¹ 
â”‚   â”œâ”€â”€ memory.py               # è®°å¿†ç®¡ç†å™¨
â”‚   â”œâ”€â”€ model_provider.py       # æ¨¡å‹æä¾›è€…
â”‚   â”œâ”€â”€ feedback.py             # åé¦ˆå¤„ç†å™¨
â”‚   â”œâ”€â”€ adaptation.py           # è‡ªé€‚åº”å­¦ä¹ 
â”‚   â””â”€â”€ fewshot.py              # Few-shotç®¡ç†
â”œâ”€â”€ daml-rag-adapters/          # ğŸ”Œ é¢†åŸŸé€‚é…å™¨
â”‚   â”œâ”€â”€ fitness/                # å¥èº«é¢†åŸŸé€‚é…å™¨
â”‚   â”œâ”€â”€ healthcare/             # åŒ»ç–—é¢†åŸŸé€‚é…å™¨
â”‚   â”œâ”€â”€ education/              # æ•™è‚²é¢†åŸŸé€‚é…å™¨
â”‚   â””â”€â”€ base/adapter.py         # é€‚é…å™¨åŸºç±»
â”œâ”€â”€ daml-rag-cli/               # ğŸš€ å‘½ä»¤è¡Œå·¥å…·
â”‚   â”œâ”€â”€ cli.py                  # CLIä¸»ç¨‹åº
â”‚   â”œâ”€â”€ commands/               # å‘½ä»¤å®ç°
â”‚   â””â”€â”€ templates/              # é¡¹ç›®æ¨¡æ¿
â””â”€â”€ examples/                   # ğŸ“š ç¤ºä¾‹é¡¹ç›®
    â”œâ”€â”€ fitness-coach/          # å¥èº«æ•™ç»ƒåº”ç”¨
    â”œâ”€â”€ medical-assistant/      # åŒ»ç–—åŠ©æ‰‹åº”ç”¨
    â””â”€â”€ education-tutor/        # æ•™è‚²è¾…å¯¼åº”ç”¨
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…

```bash
pip install daml-rag-framework
```

### åˆ›å»ºæ–°é¡¹ç›®

```bash
# åˆ›å»ºå¥èº«é¢†åŸŸAIåº”ç”¨
daml-rag init my-fitness-app --domain fitness

# åˆ›å»ºåŒ»ç–—é¢†åŸŸAIåº”ç”¨
daml-rag init my-medical-app --domain healthcare

# åˆ›å»ºè‡ªå®šä¹‰é¢†åŸŸAIåº”ç”¨
daml-rag init my-custom-app --template custom
```

### åŸºæœ¬ä½¿ç”¨

```python
from daml_rag import DAMLRAGFramework, DAMLRAGConfig
from daml_rag_adapters.fitness import FitnessDomainAdapter

async def main():
    # åŠ è½½é…ç½®
    config = DAMLRAGConfig.from_file("config.yaml")

    # åˆ›å»ºæ¡†æ¶å®ä¾‹
    framework = DAMLRAGFramework(config)

    # åˆå§‹åŒ–é¢†åŸŸé€‚é…å™¨
    adapter = FitnessDomainAdapter(config.domain_config)
    await adapter.initialize()

    # åˆå§‹åŒ–æ¡†æ¶
    await framework.initialize()

    # å¤„ç†ç”¨æˆ·æŸ¥è¯¢
    result = await framework.process_query("æˆ‘æƒ³åˆ¶å®šä¸€ä¸ªå¢è‚Œè®¡åˆ’")
    print(result.response)

if __name__ == "__main__":
    asyncio.run(main())
```

### é…ç½®æ–‡ä»¶ç¤ºä¾‹

```yaml
# config.yaml
domain: fitness
debug: false

retrieval:
  vector_model: "BAAI/bge-base-zh-v1.5"
  top_k: 5
  similarity_threshold: 0.6
  cache_ttl: 300
  enable_kg: true
  enable_rules: true

orchestration:
  max_parallel_tasks: 10
  timeout_seconds: 30
  retry_attempts: 3
  enable_caching: true

learning:
  teacher_model: "deepseek"
  student_model: "ollama-qwen2.5"
  experience_threshold: 3.5
  feedback_weight: 0.8
  adaptive_threshold: 0.7

domain_config:
  knowledge_graph_path: "./data/knowledge_graph.db"
  mcp_servers:
    - name: "user-profile"
      command: "python"
      args: ["user-profile-stdio/server.py"]
    - name: "professional-coach"
      command: "python"
      args: ["professional-coach-stdio/server.py"]
```

## ğŸ“Š Current Status / å½“å‰çŠ¶æ€

**âš ï¸ Project Status: Production Preparation (Frontend Completion)**

**é¡¹ç›®çŠ¶æ€ï¼šç”Ÿäº§å‡†å¤‡ï¼ˆå‰ç«¯å®Œå–„ä¸­ï¼‰**

### Actual Measured Data / å®é™…æµ‹é‡æ•°æ®

| Metric æŒ‡æ ‡ | Current å½“å‰ | Notes è¯´æ˜ |
|------------|-------------|-----------|
| **Token/Query (Simple)** | 500-800 | DeepSeek + User Profile MCP |
| **Response Time** | **~20s** | âš ï¸ Not optimized, caching needed |
| **Project Stage** | Production Prep | Preparing for deployment |
| **MCP Tools Implemented** | 14/14 âœ… | All tools completed |
| **Docker Status** | In Use | Local deployment ready |
| **Frontend Status** | In Progress | Completing before deployment |

### Current Issues / å½“å‰é—®é¢˜

**âš ï¸ Known Performance Issues:**

- **Slow Response**: ~20 seconds for simple queries
  - Cause: Unoptimized graph queries, no caching mechanism
  - Cause: Multiple sequential MCP calls, no parallelization
  - Status: Optimization planned for Phase 1
  
- **Frontend Completion**: In progress
  - Tools backend: âœ… Complete (14/14)
  - Frontend UI: ğŸš§ Completing
  - Docker deployment: âœ… Ready locally

- **Production Deployment**: Preparing
  - Local Docker: âœ… In use
  - Production deployment: ğŸš§ After frontend completion
  - Performance optimization: â³ Planned

### Known Limitations / å·²çŸ¥é™åˆ¶

**âš ï¸ IMPORTANT: Read [LIMITATIONS.md](LIMITATIONS.md) before use!**

**âš ï¸ é‡è¦ï¼šä½¿ç”¨å‰è¯·é˜…è¯» [LIMITATIONS.md](LIMITATIONS.md)ï¼**

Key limitations:

- **Hardware Requirements**: Minimum 16GB RAM, 32GB+ recommended
- **Response Time**: ~20 seconds (BUILD_BODY case on laptop, not optimized)
- **Scale Limits**: Performance degrades with >30K nodes on single machine
- **Deployment**: Distributed deployment recommended for production

å…³é”®é™åˆ¶ï¼š

- **ç¡¬ä»¶éœ€æ±‚**ï¼šæœ€ä½16GBå†…å­˜ï¼Œæ¨è32GB+
- **å“åº”æ—¶é—´**ï¼š~20ç§’ï¼ˆBUILD_BODYç¬”è®°æœ¬æ¡ˆä¾‹ï¼Œæœªä¼˜åŒ–ï¼‰
- **è§„æ¨¡é™åˆ¶**ï¼šå•æœºè¶…è¿‡30KèŠ‚ç‚¹æ€§èƒ½ä¸‹é™
- **éƒ¨ç½²**ï¼šç”Ÿäº§ç¯å¢ƒå»ºè®®åˆ†å¸ƒå¼éƒ¨ç½²

See detailed analysis in [LIMITATIONS.md](LIMITATIONS.md).

### Design Targets (Not Yet Validated) / è®¾è®¡ç›®æ ‡ï¼ˆæœªéªŒè¯ï¼‰

The following are **theoretical design goals**, not validated metrics:

ä»¥ä¸‹æ˜¯**ç†è®ºè®¾è®¡ç›®æ ‡**ï¼ŒééªŒè¯æŒ‡æ ‡ï¼š

- ğŸ¯ Token efficiency through GraphRAG hybrid retrieval
- ğŸ¯ Cost optimization via teacher-student collaboration  
- ğŸ¯ Quality improvement through structured knowledge
- ğŸ¯ Fast retrieval via vector + graph + rules

**Status**: Implementation in progress, benchmarks pending.

**çŠ¶æ€**ï¼šå®æ–½è¿›è¡Œä¸­ï¼ŒåŸºå‡†æµ‹è¯•å¾…è¿›è¡Œã€‚

---

## ğŸ“š Documentation / æ–‡æ¡£

### Essential Reading / å¿…è¯»æ–‡æ¡£

- **[LIMITATIONS.md](LIMITATIONS.md)** âš ï¸ - Limitations and constraints (READ FIRST!)
- **[LIMITATIONS.md](LIMITATIONS.md)** âš ï¸ - é™åˆ¶å’Œçº¦æŸï¼ˆå¿…è¯»ï¼ï¼‰

### Theory / ç†è®ºåŸºç¡€

- [00-ç†è®ºæ¼”è¿›å†å²](docs/theory/00-ç†è®ºæ¼”è¿›å†å².md) / [Theory Evolution](docs/theory/00-THEORY_EVOLUTION.md)
- [01-GraphRAGæ··åˆæ£€ç´¢ç†è®º](docs/theory/01-GraphRAGæ··åˆæ£€ç´¢ç†è®º.md) / [GraphRAG Hybrid Retrieval](docs/theory/01-GraphRAG-Hybrid-Retrieval.md)
- [02-æ¨ç†æ—¶ä¸Šä¸‹æ–‡å­¦ä¹ ç†è®º](docs/theory/02-æ¨ç†æ—¶ä¸Šä¸‹æ–‡å­¦ä¹ ç†è®º.md) / [In-Context Learning](docs/theory/02-In-Context-Learning.md)
- [æ¡†æ¶æ€»è§ˆ](docs/theory/æ¡†æ¶æ€»è§ˆ.md) / [Framework Overview](docs/theory/FRAMEWORK_OVERVIEW.md)

### Case Studies / æ¡ˆä¾‹ç ”ç©¶

- [BUILD_BODY Case Study](examples/BUILD_BODY_CASE_STUDY.md) (Coming soon) - Reference implementation
- [BUILD_BODYæ¡ˆä¾‹ç ”ç©¶](examples/BUILD_BODY_CASE_STUDY.md)ï¼ˆå³å°†æ¨å‡ºï¼‰- å‚è€ƒå®ç°

### Guides / æŒ‡å—

- [Quick Start / å¿«é€Ÿå¼€å§‹](docs/tutorials/quickstart.md) (Coming soon)
- [Architecture Design / æ¶æ„è®¾è®¡](docs/architecture/) (Coming soon)
- [API Reference / APIæ–‡æ¡£](docs/api/) (Coming soon)
- [Deployment Guide / éƒ¨ç½²æŒ‡å—](docs/tutorials/deployment.md) (Coming soon)

### References / å‚è€ƒæ–‡çŒ®

- [Complete Bibliography / å®Œæ•´å‚è€ƒæ–‡çŒ®](REFERENCES.md)
- [Citation / å­¦æœ¯å¼•ç”¨](CITATION.cff)
- [Academic Corrections / å­¦æœ¯ä¿®æ­£](ACADEMIC-CORRECTIONS-SUMMARY.md) - Transparency record

## ğŸ“– Citation / å­¦æœ¯å¼•ç”¨

If you use DAML-RAG in your research or project, please cite:

```bibtex
@software{daml_rag_2024,
  title={DAML-RAG: Domain-Adaptive Meta-Learning RAG Framework},
  author={è–›å°å· (Xue Xiaochuan)},
  year={2025},
  version={1.0.0},
  url={https://github.com/...}
}
```

See [CITATION.cff](CITATION.cff) for detailed citation metadata.

**Copyright Â© 2025 è–›å°å· (Xue Xiaochuan). All rights reserved.**

---

## ğŸ¤ Contributing / è´¡çŒ®

Contributions are welcome! Please check:
- [CONTRIBUTING.md](CONTRIBUTING.md) (Coming soon)
- [CODE_OF_CONDUCT.md](CODE_OF_CONDUCT.md) (Coming soon)

æ¬¢è¿è´¡çŒ®ï¼è¯·æŸ¥çœ‹è´¡çŒ®æŒ‡å—ã€‚

---

## ğŸ“„ License / è®¸å¯è¯

**Copyright Â© 2025 è–›å°å· (Xue Xiaochuan). All rights reserved.**

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

**ç‰ˆæƒæ‰€æœ‰ Â© 2025 è–›å°å·ã€‚ä¿ç•™æ‰€æœ‰æƒåˆ©ã€‚**

æ ¹æ®Apache License 2.0è®¸å¯è¯æˆæƒã€‚è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

---

## ğŸ™ Acknowledgments / è‡´è°¢

Built on theoretical and practical achievements from the BUILD_BODY v2.0 project.

åŸºäº BUILD_BODY v2.0 é¡¹ç›®çš„ç†è®ºå’Œå®è·µæˆæœæ„å»ºã€‚

**Standing on the shoulders of giants:**
- RAG: Lewis et al. (2020)
- GraphRAG: Microsoft Research (2024)
- In-Context Learning: Brown et al. (2020)
- Knowledge Graphs: Hogan et al. (2021)
- MCP: Anthropic (2024)

---

**Making AI Understand Professional Domains / è®©AIæ›´æ‡‚ä¸“ä¸šé¢†åŸŸ** ğŸš€